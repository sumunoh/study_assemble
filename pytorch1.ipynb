{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMh1Dt2pmSFhlCYstHREKr2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumunoh/study_assemble/blob/main/pytorch1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9Xx-jP92OgP"
      },
      "source": [
        "# 파이토치(PyTorch)\n",
        "\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbuUgoV%2FbtqwWZvcHHX%2Fd6XzIFBEfiuFb0UvyV4A50%2Fimg.jpg\" width=\"300\">\n",
        "\n",
        "- 코드 출처: https://pytorch.org/tutorials/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cxreguz2sL0"
      },
      "source": [
        "## 파이토치의 구성요소\n",
        "\n",
        "- `torch`: 텐서를 생성하는 라이브러리\n",
        "\n",
        "- `torch.autograd`: 자동미분 기능을 제공하는 라이브러리\n",
        "\n",
        "- `torch.nn`: 신경망을 생성하는 라이브러리\n",
        "\n",
        "- `torch.multiprocessing`: 병럴처리 기능을 제공하는 라이브러리\n",
        "\n",
        "- `torch.utils`: 데이터 조작 등 유틸리티 기능 제공\n",
        "\n",
        "- `torch.legacy`(./nn/.optim): Torch로부터 포팅해온 코드\n",
        "\n",
        "- `torch.onnx`: ONNX(Open Neural Network Exchange)\n",
        "\n",
        "  - 서로 다른 프레임워크 간의 모델을 공유할 때 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb5O_aSvtHvb"
      },
      "source": [
        "## 텐서(Tensors)\n",
        "- 넘파이(NumPy)의 ndarray와 유사\n",
        "\n",
        "- GPU를 사용한 연산 가속도 가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmKIvnx0s8G6"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49IHV-qJE5FI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b83ee92b-dace-4db6-815d-4bb7ef1140f2"
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.10.0+cu111'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isUHVy-gtZeT"
      },
      "source": [
        "### 초기화 되지 않은 행렬 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PqY3cZatU0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "563ef5ec-d0e4-4e35-bd20-cb8159027c2d"
      },
      "source": [
        "x = torch.empty(4,2)\n",
        "print(x)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5.4623e-05, 3.0932e-41],\n",
            "        [3.3631e-44, 0.0000e+00],\n",
            "        [       nan, 6.4460e-44],\n",
            "        [1.1578e+27, 1.1362e+30]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPCIJ2pNteZv"
      },
      "source": [
        "### 무작위로 초기화된 행렬"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6oPj2Q9tdYx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8c1b1a5-9c23-4f84-9b97-d59a796652c3"
      },
      "source": [
        "x = torch.rand(4,2)\n",
        "print(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2519, 0.7386],\n",
            "        [0.1790, 0.3017],\n",
            "        [0.3395, 0.0277],\n",
            "        [0.9694, 0.3511]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5aHphIHtiJk"
      },
      "source": [
        "### dtype이 long, 0으로 채워진 텐서"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zykN8aMthXk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d6cabff-8794-492f-9011-8e31fb0f252f"
      },
      "source": [
        "x = torch.zeros(4,2, dtype=torch.long)\n",
        "print(x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 0],\n",
            "        [0, 0],\n",
            "        [0, 0],\n",
            "        [0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4VL8C_ctu8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dfe3b96-c9a2-4b5e-81d3-e8ba059dc54b"
      },
      "source": [
        "x = torch.tensor([3, 2.3])\n",
        "print(x)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3.0000, 2.3000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RmVBVtIt46M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af7b4b26-6b2c-4e24-89e1-396d074eca34"
      },
      "source": [
        "x = x.new_ones(2, 4, dtype=torch.double)\n",
        "print(x)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxskTUfGuPUe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbbc298e-186f-4085-b616-de326abae98d"
      },
      "source": [
        "x = torch.randn_like(x, dtype=torch.float)\n",
        "print(x)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4004, -0.9814, -0.3485, -1.1647],\n",
            "        [ 1.3984,  1.0486, -1.3234, -0.4801]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7j5sGxGvucpH"
      },
      "source": [
        "### 텐서의 크기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy-JbqKEuYIR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29dfceff-0d10-428d-9811-fbab6552a421"
      },
      "source": [
        "print(x.size())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehOg0eDwufru"
      },
      "source": [
        "## 텐서의 연산(operations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8Doc_37uh3G"
      },
      "source": [
        "### 덧셈 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw4JCYkYuef9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64f55f75-bd51-4470-fd79-427d4766ab50"
      },
      "source": [
        "print(x)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4004, -0.9814, -0.3485, -1.1647],\n",
            "        [ 1.3984,  1.0486, -1.3234, -0.4801]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa44ur1Nuj5U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cdf3e7a-b083-4c7d-aec5-0a509308fe8a"
      },
      "source": [
        "y = torch.rand(2,4)\n",
        "print(y)\n",
        "print(x+y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2997, 0.8385, 0.7855, 0.3492],\n",
            "        [0.6183, 0.9612, 0.1214, 0.7539]])\n",
            "tensor([[-0.1007, -0.1428,  0.4371, -0.8155],\n",
            "        [ 2.0167,  2.0099, -1.2020,  0.2737]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5gcOo-Ouo9B"
      },
      "source": [
        "### 덧셈2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qx-NzJhhumZx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a6eaf84-c3d0-4e75-d678-39b619340010"
      },
      "source": [
        "print(torch.add(x,y))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1007, -0.1428,  0.4371, -0.8155],\n",
            "        [ 2.0167,  2.0099, -1.2020,  0.2737]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlvrQhLuuuIr"
      },
      "source": [
        "### 덧셈3\n",
        "- 결과 텐서를 인자로 제공"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUsLAOTcur1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4842b983-bf34-4154-913b-8afa7f9a20ae"
      },
      "source": [
        "result = torch.empty(2,4)\n",
        "torch.add(x,y,out=result)\n",
        "print(result)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1007, -0.1428,  0.4371, -0.8155],\n",
            "        [ 2.0167,  2.0099, -1.2020,  0.2737]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6BdyZFSu2Ei"
      },
      "source": [
        "### 덧셈4\n",
        "- `in-place` 방식\n",
        "\n",
        "- (참고) in-place 방식\n",
        "  - in-place방식으로 텐서의 값을 변경하는 연산 뒤에는 _''가 붙음\n",
        "  - `x.copy_(y), x.t_()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu8rR4WVu0wQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70ea8a65-07d9-4af5-cb75-1ad83d36d356"
      },
      "source": [
        "print(x)\n",
        "print(y)\n",
        "y.add_(x)\n",
        "print(y)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4004, -0.9814, -0.3485, -1.1647],\n",
            "        [ 1.3984,  1.0486, -1.3234, -0.4801]])\n",
            "tensor([[0.2997, 0.8385, 0.7855, 0.3492],\n",
            "        [0.6183, 0.9612, 0.1214, 0.7539]])\n",
            "tensor([[-0.1007, -0.1428,  0.4371, -0.8155],\n",
            "        [ 2.0167,  2.0099, -1.2020,  0.2737]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo8nsrGjOw6W"
      },
      "source": [
        "### 그 외의 연산\n",
        "- `torch.sub` : 뺄셈\n",
        "\n",
        "- `torch.mul` : 곱셉\n",
        "\n",
        "- `torch.div` : 나눗셈\n",
        "\n",
        "- `torch.mm` : 내적(dot product)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S51kxzPTO1ER",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d258854e-24e4-4da7-847c-be70fa995304"
      },
      "source": [
        "x = torch.Tensor([[1,3],\n",
        "                  [5,7]])\n",
        "y = torch.Tensor([[2,4],\n",
        "                  [6,8]])\n",
        "print(x-y)\n",
        "print(torch.sub(x,y))\n",
        "print(x.sub(y))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1., -1.],\n",
            "        [-1., -1.]])\n",
            "tensor([[-1., -1.],\n",
            "        [-1., -1.]])\n",
            "tensor([[-1., -1.],\n",
            "        [-1., -1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou0dY8mkPR24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f606091e-6db2-4d03-c576-2b7291d19fc9"
      },
      "source": [
        "x = torch.Tensor([[1,3],\n",
        "                  [5,7]])\n",
        "y = torch.Tensor([[2,4],\n",
        "                  [6,8]])\n",
        "print(x*y)\n",
        "print(torch.mul(x,y))\n",
        "print(x.mul(y))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2., 12.],\n",
            "        [30., 56.]])\n",
            "tensor([[ 2., 12.],\n",
            "        [30., 56.]])\n",
            "tensor([[ 2., 12.],\n",
            "        [30., 56.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RlZZBp3PbE4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ec9baca-3d40-4ac2-cc5b-448bd74da26f"
      },
      "source": [
        "x = torch.Tensor([[1,3],\n",
        "                  [5,7]])\n",
        "y = torch.Tensor([[2,4],\n",
        "                  [6,8]])\n",
        "print(x/y)\n",
        "print(torch.div(x,y))\n",
        "print(x.div(y))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5000, 0.7500],\n",
            "        [0.8333, 0.8750]])\n",
            "tensor([[0.5000, 0.7500],\n",
            "        [0.8333, 0.8750]])\n",
            "tensor([[0.5000, 0.7500],\n",
            "        [0.8333, 0.8750]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MR-ofE5P7VC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "278a0c89-3d35-432e-aa03-7ad940bb6e48"
      },
      "source": [
        "# 행렬곱\n",
        "x = torch.Tensor([[1,3],\n",
        "                  [5,7]])\n",
        "y = torch.Tensor([[2,4],\n",
        "                  [6,8]])\n",
        "print(torch.mm(x,y))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[20., 28.],\n",
            "        [52., 76.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8URGwHE_NjDi"
      },
      "source": [
        "## 텐서의 조작(manipulations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCsdZIPTvG53"
      },
      "source": [
        "### 인덱싱\n",
        "- 넘파이처럼 인덱싱 사용가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF2DE8kzvOs3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ed99f61-1144-481a-a02b-b436e9a7fd59"
      },
      "source": [
        "print(x)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 3.],\n",
            "        [5., 7.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQtBH3r3u7c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55030d2e-eeb1-4621-ff3f-05847c69297a"
      },
      "source": [
        "print(x[:, 1])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 7.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEscXddKvQ5l"
      },
      "source": [
        "### view\n",
        "- 텐서의 크기(size)나 모양(shape)을 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwhWeqhLvKKj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd830d20-cc15-4910-ca46-22f77a848d06"
      },
      "source": [
        "x = torch.randn(4, 5)\n",
        "y = x.view(20)\n",
        "z = x.view(5, -1)\n",
        "\n",
        "print(x)\n",
        "print(y)\n",
        "print(z)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.4639, -2.3990,  0.6991,  0.4616, -0.8157],\n",
            "        [-0.0836, -0.9492, -0.0160, -0.5664, -1.0807],\n",
            "        [-0.3419, -1.0234,  0.3289,  1.0998,  0.8417],\n",
            "        [ 1.7682, -0.0242,  0.1195,  0.6466,  1.1310]])\n",
            "tensor([ 0.4639, -2.3990,  0.6991,  0.4616, -0.8157, -0.0836, -0.9492, -0.0160,\n",
            "        -0.5664, -1.0807, -0.3419, -1.0234,  0.3289,  1.0998,  0.8417,  1.7682,\n",
            "        -0.0242,  0.1195,  0.6466,  1.1310])\n",
            "tensor([[ 0.4639, -2.3990,  0.6991,  0.4616],\n",
            "        [-0.8157, -0.0836, -0.9492, -0.0160],\n",
            "        [-0.5664, -1.0807, -0.3419, -1.0234],\n",
            "        [ 0.3289,  1.0998,  0.8417,  1.7682],\n",
            "        [-0.0242,  0.1195,  0.6466,  1.1310]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBY_wuIRvf5j"
      },
      "source": [
        "### item\n",
        "- 텐서에 값이 단 하나라도 존재하면 숫자값을 얻을 수 있음\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0W24QqpvcmV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c662be4-b318-4621-907d-9cb4f206ea2d"
      },
      "source": [
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.item()) # 실제값 출력\n",
        "print(x.dtype)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3323])\n",
            "0.33228033781051636\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1sCUVwC3Nua"
      },
      "source": [
        "- 스칼라값 하나만 존재해야함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl4_FAgd3Lt9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "785652f9-5a74-4646-fae4-53b1fab0c18a"
      },
      "source": [
        "x = torch.randn(2)\n",
        "print(x)\n",
        "print(x.item())\n",
        "print(x.dtype)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.1161, -0.1482])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-7c023f92a1c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uThndsy5M6wM"
      },
      "source": [
        "### squeeze \n",
        "- 차원을 축소(제거)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OF3rOavnRxgM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d033464-46d0-4867-8a37-de72aab4e0c6"
      },
      "source": [
        "tensor = torch.rand(1,3,3)\n",
        "print(tensor)\n",
        "tensor.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.2876, 0.5879, 0.0566],\n",
            "         [0.1585, 0.1388, 0.6901],\n",
            "         [0.9074, 0.5102, 0.0075]]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2jq0jHJR5Jw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6894bf5d-6425-4758-c613-d3f15b6b440c"
      },
      "source": [
        "t = tensor.squeeze()\n",
        "\n",
        "print(t)\n",
        "print(t.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2876, 0.5879, 0.0566],\n",
            "        [0.1585, 0.1388, 0.6901],\n",
            "        [0.9074, 0.5102, 0.0075]])\n",
            "torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COv-dnTYNJ8Z"
      },
      "source": [
        "### unsqueeze\n",
        "- 차원을 증가(생성)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFxaHGY1NOBo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f16f108-6bcd-4390-92c2-274aaa885d16"
      },
      "source": [
        "tensor = torch.rand(1,3,3)\n",
        "print(tensor)\n",
        "print(tensor.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.7629, 0.1147, 0.1132],\n",
            "         [0.7027, 0.2210, 0.8526],\n",
            "         [0.2541, 0.4757, 0.8917]]])\n",
            "torch.Size([1, 3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6sa4tJ7SA8G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4e25351-1727-4f76-8524-884ed7a828d6"
      },
      "source": [
        "t = tensor.unsqueeze(dim=0)\n",
        "\n",
        "print(t)\n",
        "print(t.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[0.7629, 0.1147, 0.1132],\n",
            "          [0.7027, 0.2210, 0.8526],\n",
            "          [0.2541, 0.4757, 0.8917]]]])\n",
            "torch.Size([1, 1, 3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C_oa9JANOa6"
      },
      "source": [
        "### stack\n",
        "- 텐서간 결합"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3x_XaUYNOuc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63742271-766b-4505-b147-96ef0fee8efc"
      },
      "source": [
        "x = torch.FloatTensor([1, 4])\n",
        "y = torch.FloatTensor([2, 5])\n",
        "z = torch.FloatTensor([3, 6])\n",
        "\n",
        "print(torch.stack([x,y,z]))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 4.],\n",
            "        [2., 5.],\n",
            "        [3., 6.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmJscbfg35-c"
      },
      "source": [
        "### cat\n",
        "- 텐서를 결합하는 메소드(concatenate)\n",
        "\n",
        "- 넘파이의 `stack`과 유사하지만, 쌓을 dim이 존재해야함\n",
        "  - 예를 들어, 해당 차원을 늘려준 후 결합\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mv3zlaNm37P1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70b40bca-34c2-450a-d067-e5fa7228a293"
      },
      "source": [
        "a = torch.randn(1,3,3)\n",
        "b = torch.randn(1,3,3)\n",
        "c = torch.cat((a,b), dim=1)\n",
        "\n",
        "print(c)\n",
        "print(c.size())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.0378,  0.3127,  0.8107],\n",
            "         [-0.4458, -1.1158, -1.4534],\n",
            "         [ 1.2015, -1.1225, -1.4003],\n",
            "         [-0.0212,  1.5646, -0.5531],\n",
            "         [-1.2865,  0.9630, -0.8783],\n",
            "         [ 0.4378, -0.3369, -1.4034]]])\n",
            "torch.Size([1, 6, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gGXnOAqQTmG"
      },
      "source": [
        "### chuck\n",
        "- 텐서를 여러 개로 나눌 때 사용\n",
        "\n",
        "- 몇 개의 텐서로 나눌 것이냐"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNV80VzPQZgG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "453a1dcc-6253-4baa-fa37-d849e16c1ddf"
      },
      "source": [
        "tensor = torch.rand(3, 6)\n",
        "t1, t2, t3 = torch.chunk(tensor, 3, dim=1)\n",
        "\n",
        "print(tensor)\n",
        "print(t1)\n",
        "print(t2)\n",
        "print(t3)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8795, 0.2430, 0.4649, 0.4619, 0.7860, 0.6349],\n",
            "        [0.6371, 0.5261, 0.7108, 0.1003, 0.4192, 0.6017],\n",
            "        [0.3332, 0.5087, 0.2694, 0.4892, 0.9145, 0.0532]])\n",
            "tensor([[0.8795, 0.2430],\n",
            "        [0.6371, 0.5261],\n",
            "        [0.3332, 0.5087]])\n",
            "tensor([[0.4649, 0.4619],\n",
            "        [0.7108, 0.1003],\n",
            "        [0.2694, 0.4892]])\n",
            "tensor([[0.7860, 0.6349],\n",
            "        [0.4192, 0.6017],\n",
            "        [0.9145, 0.0532]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U0Qb0jWQgm-"
      },
      "source": [
        "### split\n",
        "- `chunck`와 동일한 기능이지만 조금 다름\n",
        "\n",
        "- 하나의 텐서당 크기가 얼마이냐"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V6DDnLVQqxz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40ba4335-3787-451e-d10c-fad1f112a582"
      },
      "source": [
        "tensor = torch.rand(3,6)\n",
        "t1, t2 = torch.split(tensor, 3, dim=1)\n",
        "\n",
        "print(tensor)\n",
        "print(t1)\n",
        "print(t2)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9999, 0.3581, 0.7677, 0.7497, 0.4772, 0.7898],\n",
            "        [0.9771, 0.9998, 0.5682, 0.5820, 0.8552, 0.2342],\n",
            "        [0.4835, 0.8219, 0.4104, 0.9740, 0.6383, 0.0251]])\n",
            "tensor([[0.9999, 0.3581, 0.7677],\n",
            "        [0.9771, 0.9998, 0.5682],\n",
            "        [0.4835, 0.8219, 0.4104]])\n",
            "tensor([[0.7497, 0.4772, 0.7898],\n",
            "        [0.5820, 0.8552, 0.2342],\n",
            "        [0.9740, 0.6383, 0.0251]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "estSwhCgvta6"
      },
      "source": [
        "### torch ↔ numpy\n",
        "- Torch Tensor(텐서)를 Numpy array(배열)로 변환 가능\n",
        "\n",
        "  - `numpy()`\n",
        "  - `from_numpy()`\n",
        "\n",
        "- (참고)\n",
        "  - Tensor가 CPU상에 있다면 Numpy 배열은 메모리 공간을 공유하므로 하나가 변하면, 다른 하나도 변함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxHI7c_yvmAT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3359c3a2-8153-4a98-d693-b183553f9208"
      },
      "source": [
        "a = torch.ones(7)\n",
        "print(a)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whbrhokHwJ3A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74687373-e4f0-49e3-e603-7f5c44a21622"
      },
      "source": [
        "b = a.numpy()\n",
        "print(b)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5StIhUWDwQjA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0afc86d4-d622-417d-e2d0-ba3044245871"
      },
      "source": [
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 2., 2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RNS5-cRwTt8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b53ef245-84ed-4a6c-a763-17abe4ee6814"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "a = np.ones(7)\n",
        "b = torch.from_numpy(a)\n",
        "np.add(a, 1, out=a)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2. 2. 2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-ZaxSvLxEej"
      },
      "source": [
        "## CUDA Tensors\n",
        "- `.to` 메소드를 사용하여 텐서를 어떠한 장치로도 옮길 수 있음\n",
        "  - 예) cpu, gpu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkaQznCRxpUj"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCnC0x2Rxpbk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7d0daf9-33a2-4ffd-ccea-eda28169e326"
      },
      "source": [
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.item())\n",
        "print(x.dtype)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.4738])\n",
            "-0.4737919270992279\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcSsFLkDw-nI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89dfeebd-d204-419c-d3d4-6781a7bb2d5f"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "y = torch.ones_like(x, device=device)\n",
        "x = x.to(device)\n",
        "z = x + y\n",
        "print(device)\n",
        "print(z)\n",
        "print(z.to('cpu', torch.double))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "tensor([0.5262], device='cuda:0')\n",
            "tensor([0.5262], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKqiGvLWx2nk"
      },
      "source": [
        "## AUTOGRAD (자동미분)\n",
        "- autograd 패키지는 Tensor의 모든 연산에 대해 **자동 미분** 제공\n",
        "\n",
        "- 이는 코드를 어떻게 작성하여 실행하느냐에 따라 역전파가 정의된다는 뜻\n",
        "\n",
        "- backprop를 위한 미분값을 자동으로 계산\n",
        "\n",
        "\n",
        "-----------------------------------------------36:00"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zH41l-MyMHi"
      },
      "source": [
        "### Tensor\n",
        "\n",
        "- data: tensor형태의 데이터\n",
        "\n",
        "- grad: data가 거쳐온 layer에 대한 미분값 저장\n",
        "\n",
        "- grad_fn: 미분값을 계산한 함수에 대한 정보 저장 (어떤 함수에 대해서 backprop 했는지)\n",
        "\n",
        "- `requires_grad` 속성을 `True`로 설정하면, 해당 텐서에서 이루어지는 모든 연산들을 추적하기 시작\n",
        "\n",
        "- 계산이 완료된 후, `.backward()`를 호출하면 자동으로 `gradient`를 계산할 수 있으며, `.grad` 속성에 누적됨\n",
        "\n",
        "- 기록을 추적하는 것을 중단하게 하려면, `.detach()`를 호출하여 연산기록으로부터 분리\n",
        "\n",
        "- 기록을 추적하는 것을 방지하기 위해 코드 블럭을 `with torch.no_grad():`로 감싸면 `gradient`는 필요없지만, `requires_grad=True`로 설정되어 학습 가능한 매개변수를 갖는 모델을 평가(evaluate)할 때 유용\n",
        "\n",
        "- Autograd 구현에서 매우 중요한 클래스 : `Function` 클래스"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipdk_1jfx47I"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "S8oNfUh6Kqtp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljNU-r9p0Rpo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3163541a-9052-4371-c462-0081f0dafefb"
      },
      "source": [
        "x = torch.ones(3, 3, requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or6sQ4EB0UYz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71e0c834-f77f-4344-8ec8-246409879846"
      },
      "source": [
        "y =x + 5\n",
        "print(y)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6., 6., 6.],\n",
            "        [6., 6., 6.],\n",
            "        [6., 6., 6.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuQ7xDmu0Wpj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa55a271-6de2-4f71-e275-46a5329eca51"
      },
      "source": [
        "print(y.grad_fn)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<AddBackward0 object at 0x7f1860f4cf10>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_2iM-Zq0ZdG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b74ee48d-dad2-4268-9603-0646c98bb5a5"
      },
      "source": [
        "z = y * y * 2\n",
        "out = z.mean()\n",
        "\n",
        "print(z, out)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[72., 72., 72.],\n",
            "        [72., 72., 72.],\n",
            "        [72., 72., 72.]], grad_fn=<MulBackward0>) tensor(72., grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aZ8SWn_0nqt"
      },
      "source": [
        "- `requires_grad_(...)`는 기존 텐서의 `requires_grad`값을 바꿔치기(`in-place`)하여 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHGROgrM0ebO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "985740c5-3228-43c4-bc09-26e23ee15240"
      },
      "source": [
        "a = torch.randn(3,3)\n",
        "a = ((a*3)/(a-1))\n",
        "print(a.requires_grad)\n",
        "\n",
        "a.requires_grad_(True)\n",
        "print(a.requires_grad)\n",
        "\n",
        "b = (a*a).sum()\n",
        "print(b.grad_fn)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "True\n",
            "<SumBackward0 object at 0x7f1860ebab10>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiEn_stZ1VgU"
      },
      "source": [
        "### 기울기(Gradient)\n",
        "- 역전파: `.backward()`를 통해 역전파 계산 가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tdoN9p-1kn4"
      },
      "source": [
        "out.backward()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CixGTXbV1B9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a3f53b8-cf9a-458c-e845-71ff69685233"
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.6667, 2.6667, 2.6667],\n",
            "        [2.6667, 2.6667, 2.6667],\n",
            "        [2.6667, 2.6667, 2.6667]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SY63Mcc-1iNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f84afe43-8d8e-4655-cea2-6373a943ee4e"
      },
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y= x+2\n",
        "while y.data.norm() < 1000:\n",
        "  y = y* 2\n",
        "\n",
        "  print(y)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4.1157, 3.8672, 7.8516], grad_fn=<MulBackward0>)\n",
            "tensor([ 8.2313,  7.7345, 15.7033], grad_fn=<MulBackward0>)\n",
            "tensor([16.4627, 15.4690, 31.4066], grad_fn=<MulBackward0>)\n",
            "tensor([32.9254, 30.9380, 62.8132], grad_fn=<MulBackward0>)\n",
            "tensor([ 65.8508,  61.8760, 125.6264], grad_fn=<MulBackward0>)\n",
            "tensor([131.7015, 123.7519, 251.2528], grad_fn=<MulBackward0>)\n",
            "tensor([263.4031, 247.5039, 502.5056], grad_fn=<MulBackward0>)\n",
            "tensor([ 526.8062,  495.0078, 1005.0112], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPaVAbIT3gx_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b4c145d-e3b3-404c-d2e8-1ff9acb132dc"
      },
      "source": [
        "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
        "y.backward(v)\n",
        "\n",
        "print(x.grad)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.5600e+01, 2.5600e+02, 2.5600e-02])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b9amArPXtcX"
      },
      "source": [
        "- `with torch.no_grad()`를 사용하여 gradient의 업데이트를 하지 않음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weeIe5_Z3jVe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df6c6182-6984-42b3-b376-96e8863d475a"
      },
      "source": [
        "print(x.requires_grad)\n",
        "print((x ** 2).requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "  print((x ** 2).requires_grad)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLcTLVRSmCdH"
      },
      "source": [
        "- `detach()`: 내용물(content)은 같지만 require_grad가 다른 새로운 Tensor를 가져올 때"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALcth7Ew3l7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "778392bc-d25c-4708-fa9a-a92909882c6a"
      },
      "source": [
        "print(x.requires_grad)\n",
        "y = x.detach()\n",
        "print(y.requires_grad)\n",
        "print(x.eq(y).all())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n",
            "tensor(True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSarysrqBh9D"
      },
      "source": [
        "### 자동 미분 흐름 다시 보기(1)\n",
        "- 계산 흐름  \n",
        "  $a \\rightarrow b  \\rightarrow c  \\rightarrow out $\n",
        "\n",
        "<br>\n",
        "\n",
        "## $\\quad \\frac{\\partial out}{\\partial a} = ?$\n",
        "- `backward()`를 통해  \n",
        "  $a \\leftarrow b  \\leftarrow c  \\leftarrow out $을 계산하면  \n",
        "    $\\frac{\\partial out}{\\partial a}$값이 `a.grad`에 채워짐\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUAc1etP3oBc"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCW7dq9uB89T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "284ea07b-ce94-406d-ce4a-576ee45adf96"
      },
      "source": [
        "a = torch.ones(2,2)\n",
        "print(a)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AyyGy49FLz9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da97899e-e23b-4b45-ae5b-6aa5770196b3"
      },
      "source": [
        "a = torch.ones(2,2,requires_grad=True)\n",
        "print(a)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmmJa-hvFPGH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4568662d-3a3c-4c9f-b80b-42984952f96c"
      },
      "source": [
        "print(\"a.data:\", a)\n",
        "print(\"a.grad:\", a.grad)\n",
        "print(\"a.grad_fn:\", a.grad_fn)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a.data: tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n",
            "a.grad: None\n",
            "a.grad_fn: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCwhTsiHGCmG"
      },
      "source": [
        "- $b = a + 2$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUPt042iF9V1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcacc38f-3bc2-4e87-8f8d-0ba40b3a11ac"
      },
      "source": [
        "b = a + 2 \n",
        "print(b)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cw2zoq9GHLF"
      },
      "source": [
        "- $c = b^2$ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRDS6gP0GFZG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd52e121-4d8b-4828-dedb-b79b25e9c58a"
      },
      "source": [
        "c = b**2\n",
        "print(c)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[9., 9.],\n",
            "        [9., 9.]], grad_fn=<PowBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VynoiUywGSwh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcf2cc08-1428-45d2-b5bb-cb62fd7c3e5c"
      },
      "source": [
        "out = c.sum()\n",
        "print(out)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(36., grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3ryJon9GeMn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dd2b077-0c5a-49c3-f783-ca3aebbc67c1"
      },
      "source": [
        "print(out)\n",
        "out.backward()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(36., grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0aoNsPDHsoG"
      },
      "source": [
        "- a의 `grad_fn`이 None인 이유  \n",
        "  직접적으로 계산한 부분이 없었기 때문"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bccI4vIWGgqj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c27c733b-e68b-49e3-dc41-8bd601a66825"
      },
      "source": [
        "print(\"a.data:\", a.data)\n",
        "print(\"a.grad:\", a.grad)\n",
        "print(\"a.grad_fn:\", a.grad_fn)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a.data: tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "a.grad: tensor([[6., 6.],\n",
            "        [6., 6.]])\n",
            "a.grad_fn: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oka1mkadHq-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "148cca80-bb88-4fc1-96a6-851287e89660"
      },
      "source": [
        "print(\"b.data:\", b.data)\n",
        "print(\"b.grad:\", b.grad)\n",
        "print(\"b.grad_fn:\", b.grad_fn)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b.data: tensor([[3., 3.],\n",
            "        [3., 3.]])\n",
            "b.grad: None\n",
            "b.grad_fn: <AddBackward0 object at 0x7f1853d5f390>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:1013: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten/src/ATen/core/TensorBody.h:417.)\n",
            "  return self._grad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiYNajdLccUF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cee682cc-423a-4d3a-f5e5-17b45ef2a8e1"
      },
      "source": [
        "print(\"c.data:\", c.data)\n",
        "print(\"c.grad:\", c.grad)\n",
        "print(\"c.grad_fn:\", c.grad_fn)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c.data: tensor([[9., 9.],\n",
            "        [9., 9.]])\n",
            "c.grad: None\n",
            "c.grad_fn: <PowBackward0 object at 0x7f1853e439d0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:1013: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten/src/ATen/core/TensorBody.h:417.)\n",
            "  return self._grad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcLoMYite0vU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70dcbc31-c637-4cc7-f60e-a2e1cf3ce219"
      },
      "source": [
        "print(\"out.data:\", out.data)\n",
        "print(\"out.grad:\", out.grad)\n",
        "print(\"out.grad_fn:\", out.grad_fn)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out.data: tensor(36.)\n",
            "out.grad: None\n",
            "out.grad_fn: <SumBackward0 object at 0x7f1853e310d0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:1013: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten/src/ATen/core/TensorBody.h:417.)\n",
            "  return self._grad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZXgwviHfovj"
      },
      "source": [
        "### 자동 미분 흐름 다시 보기(2)\n",
        "- `grad`값을 넣어서 `backward`\n",
        "\n",
        "- 아래의 코드에서 `.grad`값이 None은 gradient값이 필요하지 않기 때문"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB6DCYXRfcI_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d87893e-a2bf-4bb8-a5f7-42255164e571"
      },
      "source": [
        "x = torch.ones(3, requires_grad=True)\n",
        "y = (x ** 2)\n",
        "z = y ** 2 + x\n",
        "out = z.sum()\n",
        "print(out)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(6., grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVo-glm8fvFv"
      },
      "source": [
        "grad = torch.Tensor([0.1, 1, 100])\n",
        "z.backward(grad)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdBklrepf2qq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "413499cd-81ef-41c8-a29a-21db20f2bbbd"
      },
      "source": [
        "print(\"x.data:\", x.data)\n",
        "print(\"x.grad:\", x.grad)\n",
        "print(\"x.grad_fn:\", x.grad_fn)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.data: tensor([1., 1., 1.])\n",
            "x.grad: tensor([  0.5000,   5.0000, 500.0000])\n",
            "x.grad_fn: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQvUGlfRf7jU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d30f946e-f46f-4e34-b217-c34d3241520b"
      },
      "source": [
        "print(\"y.data:\", y.data)\n",
        "print(\"y.grad:\", y.grad)\n",
        "print(\"y.grad_fn:\", y.grad_fn)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y.data: tensor([1., 1., 1.])\n",
            "y.grad: None\n",
            "y.grad_fn: <PowBackward0 object at 0x7f1860f69610>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:1013: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten/src/ATen/core/TensorBody.h:417.)\n",
            "  return self._grad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7TFHdMfgxvW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05aad3b4-e1fd-4c65-9c06-321405f0c055"
      },
      "source": [
        "print(\"z.data:\", z.data)\n",
        "print(\"z.grad:\", z.grad)\n",
        "print(\"z.grad_fn:\", z.grad_fn)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "z.data: tensor([2., 2., 2.])\n",
            "z.grad: None\n",
            "z.grad_fn: <AddBackward0 object at 0x7f185c57e410>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:1013: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten/src/ATen/core/TensorBody.h:417.)\n",
            "  return self._grad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKv-osmNmWiA"
      },
      "source": [
        "## nn & nn.functional\n",
        "\n",
        "- 두 패키지가 같은 기능이지만 방식이 조금 다름\n",
        "\n",
        "- 위의 `autograd` 관련 작업들을 두 패키지를 통해 진행할 수 있음\n",
        "\n",
        "- 텐서를 직접 다룰 때 `requires_grad`와 같은 방식으로 진행할 수 있음\n",
        "\n",
        "- 결론적으로, `torch.nn`은 attribute를 활용해 state를 저장하고 활용하고,  \n",
        "  `torch.nn.functional`로 구현한 함수의 경우에는 인스턴스화 시킬 필요 없이 사용이 가능\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk8fkKq3nWP1"
      },
      "source": [
        "### nn 패키지\n",
        "\n",
        "- 주로 가중치(weights), 편향(bias)값들이 내부에서 자동으로 생성되는 레이어들을 사용할 때  \n",
        "  - 따라서, `weight`값들을 직접 선언 안함\n",
        "\n",
        "- 예시\n",
        "  - Containers\n",
        "\n",
        "  - Convolution Layers\n",
        "\n",
        "  - Pooling layers\n",
        "\n",
        "  - Padding Layers\n",
        "\n",
        "  - Non-linear Activations (weighted sum, nonlinearity)\n",
        "\n",
        "  - Non-linear Activations (other)\n",
        "\n",
        "  - Normalization Layers\n",
        "\n",
        "  - Recurrent Layers\n",
        "\n",
        "  - Transformer Layers\n",
        "\n",
        "  - Linear Layers\n",
        "\n",
        "  - Dropout Layers\n",
        "\n",
        "  - Sparse Layers\n",
        "\n",
        "  - Distance Functions\n",
        "\n",
        "  - Loss Functions\n",
        "\n",
        "  - ..\n",
        "- https://pytorch.org/docs/stable/nn.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tEtWHAsmZMy"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcjCbeEQqPSI"
      },
      "source": [
        "- Convolution Layer 예시 (1)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ7Y0tCOpkhM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09c075b9-e1f0-4751-fc48-9ec1d173583f"
      },
      "source": [
        "m = nn.Conv2d(16, 33, 3, stride=2)\n",
        "\n",
        "m = nn.Conv2d(16, 33, (3, 5), stride= (2,1), padding=(4,2))\n",
        "\n",
        "m = nn.Conv2d(16, 33, (3, 5), stride= (2,1), padding=(4,2), dilation=(3,1))\n",
        "\n",
        "input = torch.randn(20, 16, 50, 100)\n",
        "print(input)\n",
        "output = m(input)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 4.2777e-01,  2.1960e-01,  2.0563e-01,  ..., -2.9417e-01,\n",
            "            1.4362e-01, -1.0214e+00],\n",
            "          [-8.1538e-01,  2.6686e-01,  4.6236e-02,  ..., -8.3534e-01,\n",
            "           -2.1047e-01,  9.4536e-01],\n",
            "          [ 1.5583e+00, -7.6634e-01,  1.0390e+00,  ..., -9.8631e-02,\n",
            "           -1.7485e+00,  4.9604e-03],\n",
            "          ...,\n",
            "          [-4.5143e-01,  1.7381e-01, -1.5550e+00,  ..., -1.4781e+00,\n",
            "            3.3635e-01,  9.5246e-01],\n",
            "          [-3.5204e-01,  1.7681e-01,  5.8838e-02,  ...,  1.3740e+00,\n",
            "            1.1464e+00,  3.3589e-01],\n",
            "          [-6.5083e-01,  1.1004e+00, -9.8473e-01,  ..., -8.0142e-02,\n",
            "            1.3482e+00,  8.3598e-01]],\n",
            "\n",
            "         [[-1.4106e+00, -6.2471e-01, -2.1130e-02,  ...,  3.4944e-01,\n",
            "            4.9070e-01, -3.6496e-01],\n",
            "          [-9.0828e-01,  1.6438e+00, -1.1609e+00,  ...,  1.9530e+00,\n",
            "           -1.2404e+00,  9.8693e-01],\n",
            "          [-1.5706e+00, -1.7804e-01, -2.0579e+00,  ..., -8.4967e-01,\n",
            "           -3.0215e-01, -1.1402e+00],\n",
            "          ...,\n",
            "          [ 1.2879e-01, -1.4578e+00, -4.3819e-01,  ...,  2.4407e-01,\n",
            "            1.2962e+00,  1.2806e+00],\n",
            "          [-8.0821e-01,  5.5408e-01,  1.8704e-01,  ..., -4.9787e-01,\n",
            "            1.4878e+00, -7.3276e-01],\n",
            "          [-4.9853e-02, -1.0399e+00,  3.1489e-01,  ..., -4.1363e-02,\n",
            "           -1.0138e-01, -1.4822e+00]],\n",
            "\n",
            "         [[-1.4462e-01,  1.0054e+00,  5.5985e-01,  ...,  3.6260e-01,\n",
            "           -6.6302e-01,  1.2844e+00],\n",
            "          [ 7.8783e-01,  2.2730e+00,  4.3478e-01,  ..., -9.3572e-02,\n",
            "            1.9642e+00,  1.2970e+00],\n",
            "          [ 1.9271e+00,  2.6954e-01, -1.1706e+00,  ...,  1.5130e+00,\n",
            "            8.4705e-01, -8.6180e-01],\n",
            "          ...,\n",
            "          [-8.3871e-01, -5.9261e-01,  1.1335e+00,  ..., -4.7817e-01,\n",
            "            3.8877e-01,  5.5653e-01],\n",
            "          [-7.8406e-01,  4.3157e-02,  6.6959e-04,  ...,  1.1002e+00,\n",
            "            4.9536e-01,  1.8846e+00],\n",
            "          [-1.5861e+00,  5.3623e-02,  4.5662e-01,  ..., -4.0794e-01,\n",
            "            1.1481e-01, -1.7426e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.3515e+00,  1.7086e+00, -3.4378e-01,  ..., -4.3160e-02,\n",
            "           -1.5655e+00, -1.1186e+00],\n",
            "          [-1.0043e+00,  9.3076e-01, -7.9255e-01,  ...,  1.0963e-01,\n",
            "            4.9128e-01, -3.0464e-01],\n",
            "          [ 1.9715e-01,  7.1901e-02,  1.9565e+00,  ..., -3.5168e-01,\n",
            "           -2.3797e-01,  1.6237e+00],\n",
            "          ...,\n",
            "          [ 4.0317e-01,  1.8695e+00,  8.2034e-01,  ..., -1.5428e+00,\n",
            "           -2.4135e-01, -8.6104e-01],\n",
            "          [ 1.5571e+00, -2.0556e-01, -8.9255e-02,  ...,  3.2795e-01,\n",
            "            2.9141e-01, -1.4619e+00],\n",
            "          [-1.5291e-01, -7.3139e-01, -1.3781e+00,  ..., -1.1223e+00,\n",
            "            2.9131e+00,  1.1140e+00]],\n",
            "\n",
            "         [[-3.9458e-01, -1.0298e-01, -8.6351e-01,  ...,  8.6590e-01,\n",
            "            5.4011e-01,  1.3950e-01],\n",
            "          [ 5.1649e-01, -8.0967e-01,  1.3648e+00,  ..., -4.7115e-01,\n",
            "           -7.5298e-01,  7.1063e-01],\n",
            "          [-6.3431e-01,  3.8088e-01, -7.6445e-01,  ..., -5.2197e-01,\n",
            "           -9.2532e-01,  5.7228e-01],\n",
            "          ...,\n",
            "          [ 6.3567e-01, -1.3425e+00, -1.3010e-01,  ...,  1.0712e-01,\n",
            "            1.6660e+00, -1.9932e+00],\n",
            "          [-2.8737e-01,  2.4321e+00, -1.6291e+00,  ..., -1.4505e+00,\n",
            "            8.6048e-01, -1.5229e+00],\n",
            "          [-1.2981e+00,  1.7196e+00, -8.4725e-01,  ...,  4.8759e-01,\n",
            "            5.8490e-01,  7.7060e-01]],\n",
            "\n",
            "         [[-5.5095e-01, -1.1060e+00, -2.1629e+00,  ...,  1.1740e+00,\n",
            "           -1.4640e-01, -9.7638e-02],\n",
            "          [ 1.1286e+00, -7.9592e-01, -4.3701e-01,  ...,  2.2965e-01,\n",
            "           -3.6682e-01, -3.2539e-02],\n",
            "          [ 1.0620e-01,  4.2414e-01, -5.3478e-01,  ...,  2.8647e-01,\n",
            "           -8.9611e-01, -1.1919e+00],\n",
            "          ...,\n",
            "          [ 4.3608e-02, -1.1781e+00, -1.8241e+00,  ..., -3.1251e-02,\n",
            "            3.2087e-01,  4.1949e-01],\n",
            "          [-7.6636e-01, -1.8879e+00,  2.3261e-01,  ...,  6.6380e-01,\n",
            "           -3.0897e-01,  1.5498e+00],\n",
            "          [ 1.7273e+00,  8.4043e-01, -9.7127e-01,  ...,  3.0959e-01,\n",
            "           -1.1588e+00, -8.2649e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 5.7370e-02,  8.6566e-01,  3.5519e-01,  ...,  2.5334e+00,\n",
            "           -1.2219e+00,  7.8892e-01],\n",
            "          [-7.9328e-01,  1.2644e+00, -1.8918e+00,  ...,  4.2518e-01,\n",
            "            8.5711e-01, -4.6969e-01],\n",
            "          [ 1.0213e+00,  1.6237e+00, -7.8259e-02,  ...,  8.5829e-02,\n",
            "           -1.3194e+00,  7.3329e-01],\n",
            "          ...,\n",
            "          [ 1.2820e+00, -1.0302e+00,  2.6935e-01,  ...,  3.3720e-01,\n",
            "           -2.1179e+00,  1.2046e+00],\n",
            "          [-7.0350e-01, -8.7051e-03,  6.1105e-01,  ...,  1.0422e-01,\n",
            "            1.1941e-01,  4.7856e-01],\n",
            "          [-1.0352e+00, -7.2540e-01,  1.0199e+00,  ...,  1.5602e-01,\n",
            "           -1.3527e+00, -1.6942e+00]],\n",
            "\n",
            "         [[-2.6936e-01, -1.9532e+00, -2.3170e-01,  ...,  4.9690e-01,\n",
            "           -1.0522e+00,  1.5158e-02],\n",
            "          [-8.4384e-01,  1.2681e+00,  2.6614e-01,  ...,  1.6092e+00,\n",
            "           -4.4436e-01,  1.7155e+00],\n",
            "          [ 2.0163e+00,  4.4299e-01,  1.2973e-02,  ..., -7.9550e-01,\n",
            "            2.0303e-01, -1.4985e+00],\n",
            "          ...,\n",
            "          [ 7.8564e-02, -1.0181e+00, -8.4565e-01,  ...,  8.4813e-01,\n",
            "           -7.8033e-01,  3.6602e-01],\n",
            "          [-3.3251e-01, -8.9145e-01, -6.8937e-01,  ..., -5.1127e-01,\n",
            "           -4.1361e-01, -1.2684e+00],\n",
            "          [-1.3534e+00, -6.9694e-01,  8.6048e-01,  ..., -4.1743e-01,\n",
            "            1.6034e-01,  9.6289e-01]],\n",
            "\n",
            "         [[-7.0522e-01,  5.3049e-01, -3.0969e-01,  ...,  1.2013e+00,\n",
            "           -8.7452e-01,  1.9228e+00],\n",
            "          [-1.1815e-01,  1.5752e+00,  9.5324e-01,  ..., -9.9545e-01,\n",
            "            2.5467e-01, -5.2706e-01],\n",
            "          [-7.7863e-01, -1.4468e+00,  1.1044e+00,  ...,  7.8824e-01,\n",
            "            6.0571e-01, -1.6700e+00],\n",
            "          ...,\n",
            "          [ 5.3164e-01, -1.1287e+00,  1.1074e+00,  ..., -4.0714e-01,\n",
            "            1.5040e+00, -2.1207e-01],\n",
            "          [ 7.1249e-01,  1.3763e+00, -3.2429e-01,  ..., -6.6436e-01,\n",
            "           -1.0554e+00,  1.0759e-02],\n",
            "          [-1.2618e-02,  5.9096e-01,  3.2203e-01,  ...,  1.9353e+00,\n",
            "           -1.7034e-01,  9.2609e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.8507e-01,  9.2794e-01,  1.0596e-01,  ..., -2.0932e-01,\n",
            "           -5.9625e-01, -9.0919e-02],\n",
            "          [-8.3264e-01,  2.3739e-01, -3.5912e-01,  ..., -5.1730e-01,\n",
            "            5.7933e-01, -2.0317e-01],\n",
            "          [-2.7392e-01,  1.3243e+00, -1.9951e+00,  ...,  2.9481e-01,\n",
            "            1.6189e+00, -7.5173e-01],\n",
            "          ...,\n",
            "          [-1.1236e+00, -8.2562e-01, -1.4093e+00,  ...,  1.2394e-01,\n",
            "           -1.2552e+00, -5.6552e-01],\n",
            "          [-2.4675e-01,  2.2438e-01, -9.3144e-01,  ..., -2.4053e+00,\n",
            "           -1.1312e-01, -6.4251e-01],\n",
            "          [ 7.6038e-01,  3.9180e-01,  2.4445e+00,  ..., -2.1693e+00,\n",
            "           -4.0468e-01,  1.5462e+00]],\n",
            "\n",
            "         [[ 6.5347e-02,  5.1419e-01, -6.2534e-01,  ..., -8.6906e-01,\n",
            "           -4.1278e-01,  1.8739e+00],\n",
            "          [ 5.3558e-01, -1.8592e+00,  8.4045e-01,  ..., -4.6737e-01,\n",
            "            8.1853e-01,  8.6430e-01],\n",
            "          [ 4.7183e-01, -6.7365e-02,  1.3128e-01,  ..., -8.6202e-01,\n",
            "            6.2458e-01, -2.3333e-01],\n",
            "          ...,\n",
            "          [-9.9640e-01,  2.7338e-01, -4.7154e-02,  ...,  6.5719e-02,\n",
            "            1.2281e+00,  1.0528e+00],\n",
            "          [ 8.2614e-01, -1.3555e+00,  8.0557e-01,  ..., -1.1394e+00,\n",
            "            5.4539e-02, -1.3159e+00],\n",
            "          [-6.0069e-01,  5.2711e-01, -2.9108e+00,  ...,  1.2025e+00,\n",
            "            4.2554e-01, -6.7417e-01]],\n",
            "\n",
            "         [[ 1.4996e+00,  7.7164e-01,  2.2548e+00,  ..., -8.7769e-01,\n",
            "            3.7664e-01, -1.2067e+00],\n",
            "          [ 4.8446e-01,  5.7080e-01, -1.5313e+00,  ...,  6.4080e-01,\n",
            "           -3.2308e-01, -5.5189e-01],\n",
            "          [-1.1807e+00, -5.2979e-01, -1.2258e+00,  ...,  5.7278e-01,\n",
            "           -1.4923e+00, -1.2238e+00],\n",
            "          ...,\n",
            "          [-9.7438e-02, -1.2929e+00, -8.5250e-01,  ..., -4.1934e-01,\n",
            "            7.0139e-01,  1.0691e+00],\n",
            "          [-8.6104e-01, -4.4704e-01,  1.8285e+00,  ..., -4.2544e-01,\n",
            "           -2.3920e+00,  1.2785e+00],\n",
            "          [-1.4507e+00, -7.5134e-01,  9.5479e-01,  ...,  5.8567e-01,\n",
            "           -1.1793e-01,  8.6965e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 5.1559e-01,  7.4004e-01, -8.3096e-01,  ...,  4.1199e-01,\n",
            "           -7.9582e-01, -6.8379e-01],\n",
            "          [ 1.4162e+00, -9.6138e-01,  8.6698e-01,  ..., -1.3019e+00,\n",
            "           -6.1503e-01, -3.2831e-01],\n",
            "          [-9.2079e-02,  8.6536e-01,  1.2096e+00,  ...,  4.3961e-01,\n",
            "           -5.8235e-01,  5.3685e-01],\n",
            "          ...,\n",
            "          [ 1.1619e+00,  9.5543e-01, -7.1038e-01,  ..., -1.6328e-01,\n",
            "            6.1092e-01, -6.3993e-01],\n",
            "          [ 2.3941e-01, -1.2498e+00,  1.3463e-01,  ..., -1.5969e+00,\n",
            "           -1.1780e+00,  1.1660e+00],\n",
            "          [ 6.3552e-01, -6.7641e-01,  3.3312e-01,  ...,  1.3388e-01,\n",
            "            2.5475e-01,  1.4469e+00]],\n",
            "\n",
            "         [[-8.5968e-02,  4.2296e-01, -1.9480e-01,  ...,  3.6231e-01,\n",
            "            2.5053e-01, -4.4649e-01],\n",
            "          [ 4.9404e-01,  8.7022e-01, -2.8372e-01,  ..., -1.2000e+00,\n",
            "            7.8442e-01,  9.6645e-02],\n",
            "          [-6.6640e-01,  2.4100e+00,  1.6097e-01,  ..., -3.7406e-01,\n",
            "           -4.1855e-01,  3.8922e-01],\n",
            "          ...,\n",
            "          [ 6.1992e-01,  1.1626e-02, -3.5498e-01,  ...,  2.9123e-01,\n",
            "            4.1201e-01, -4.6364e-01],\n",
            "          [-2.9878e-01,  5.3045e-01,  1.9161e-01,  ...,  9.6811e-02,\n",
            "           -1.5890e+00,  3.3672e-01],\n",
            "          [ 1.8969e+00, -1.2726e-01,  3.9515e-01,  ..., -8.3217e-01,\n",
            "           -7.2180e-01, -1.0694e+00]],\n",
            "\n",
            "         [[ 7.6736e-01,  6.3573e-01, -1.8966e+00,  ..., -6.8273e-01,\n",
            "            2.4686e-01,  1.1476e+00],\n",
            "          [-4.1852e-01, -7.0811e-01, -1.6162e+00,  ..., -1.9619e+00,\n",
            "            4.8653e-01,  6.6715e-01],\n",
            "          [-1.6506e+00,  7.0948e-01,  2.8019e-01,  ..., -1.0102e+00,\n",
            "            8.8079e-02,  6.1882e-01],\n",
            "          ...,\n",
            "          [ 6.4259e-01,  6.9616e-01, -1.1220e+00,  ...,  1.4026e+00,\n",
            "            3.4633e-01,  3.8788e-01],\n",
            "          [ 1.1310e+00,  2.7184e-01,  2.3850e+00,  ..., -6.3779e-01,\n",
            "            6.7642e-01,  2.5244e-01],\n",
            "          [-7.1900e-01, -3.1194e-01,  1.7296e+00,  ..., -1.2148e+00,\n",
            "           -1.1612e+00, -1.0908e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.1217e-02,  3.1965e-01,  5.1840e-01,  ..., -3.5920e-02,\n",
            "           -8.6201e-01, -1.6020e+00],\n",
            "          [-3.2948e-01,  9.8390e-02,  1.1217e+00,  ..., -2.4546e-01,\n",
            "            7.9619e-01,  1.5898e+00],\n",
            "          [-4.9374e-01, -1.4104e+00, -3.4739e-01,  ...,  8.4411e-01,\n",
            "            2.0203e+00,  2.1438e-03],\n",
            "          ...,\n",
            "          [-1.2950e+00,  9.5193e-01,  9.2508e-01,  ..., -4.6226e-01,\n",
            "           -9.9615e-01, -5.6119e-01],\n",
            "          [-1.0671e+00,  8.5159e-01, -5.3524e-01,  ..., -3.2645e-01,\n",
            "           -2.4146e+00, -2.0213e-01],\n",
            "          [ 6.3392e-01, -3.2187e-01, -1.2643e+00,  ...,  2.1805e+00,\n",
            "            6.7675e-01,  3.6691e-01]],\n",
            "\n",
            "         [[ 5.5402e-02, -7.8909e-01, -1.7043e+00,  ...,  2.2816e+00,\n",
            "            1.1646e+00, -2.7280e-01],\n",
            "          [ 2.1582e-01,  1.5177e+00,  1.1570e-01,  ...,  1.4161e-01,\n",
            "            5.4587e-01, -4.9788e-01],\n",
            "          [-2.6126e-01,  1.5491e-01, -7.9267e-01,  ..., -2.2915e+00,\n",
            "            1.8296e-01,  6.8655e-01],\n",
            "          ...,\n",
            "          [ 7.1331e-01, -1.3623e+00, -7.4659e-01,  ..., -1.4304e+00,\n",
            "            6.6768e-02, -5.2087e-01],\n",
            "          [ 9.1553e-01, -1.1150e-01, -2.4298e-01,  ...,  7.8230e-01,\n",
            "            4.8577e-01,  5.9810e-01],\n",
            "          [-1.6180e+00, -1.0225e+00, -2.0477e+00,  ...,  4.0721e-01,\n",
            "            1.4664e-01, -1.6560e-01]],\n",
            "\n",
            "         [[ 1.0180e-01,  9.7070e-01, -4.7010e-01,  ...,  1.0083e+00,\n",
            "            7.3770e-01,  7.8728e-02],\n",
            "          [-1.0317e+00, -8.3998e-01, -1.2280e+00,  ..., -6.0474e-01,\n",
            "            9.4982e-01, -1.2726e+00],\n",
            "          [ 1.0197e+00, -4.9058e-01,  9.9258e-01,  ..., -3.6704e-01,\n",
            "           -9.4266e-01, -3.3474e-02],\n",
            "          ...,\n",
            "          [-3.3913e-01, -7.9043e-01, -5.4962e-01,  ..., -1.0079e+00,\n",
            "            1.0908e+00,  4.7693e-01],\n",
            "          [ 5.2401e-01, -9.4338e-01,  1.7182e+00,  ..., -5.6850e-01,\n",
            "           -1.7796e+00, -4.1588e-01],\n",
            "          [-4.5286e-01, -8.5341e-02,  2.4790e-01,  ...,  2.4119e-01,\n",
            "            4.3870e-01,  1.0032e+00]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 3.2433e-01,  3.3411e-01,  5.6951e-01,  ..., -1.4596e+00,\n",
            "            2.2605e+00,  5.3365e-01],\n",
            "          [-8.9498e-01,  6.5898e-01,  1.1433e+00,  ..., -2.3467e-01,\n",
            "            5.0924e-01,  1.2498e+00],\n",
            "          [ 1.1295e-01,  1.4183e-02, -1.1692e-01,  ...,  1.9663e+00,\n",
            "            1.0912e+00, -2.5554e-01],\n",
            "          ...,\n",
            "          [-4.9772e-01, -7.3114e-01,  4.5021e-01,  ...,  1.2572e+00,\n",
            "            5.0106e-01,  3.2127e-01],\n",
            "          [ 5.9065e-01, -6.1327e-01,  5.0312e-02,  ..., -3.8045e-01,\n",
            "            3.4427e-01, -1.0302e+00],\n",
            "          [-9.3648e-01, -6.7943e-01,  6.5789e-01,  ..., -2.7861e-01,\n",
            "           -5.9272e-02,  5.3240e-01]],\n",
            "\n",
            "         [[ 1.4177e+00, -1.3313e+00, -2.5856e-01,  ..., -7.3524e-01,\n",
            "           -3.3156e-01, -1.0898e+00],\n",
            "          [ 2.0052e+00, -5.6739e-01,  6.5130e-01,  ...,  2.8732e+00,\n",
            "            3.7343e-01, -1.4772e+00],\n",
            "          [-2.2768e+00,  1.7478e+00, -3.2204e-01,  ...,  1.3779e+00,\n",
            "            1.0505e+00, -3.5666e-01],\n",
            "          ...,\n",
            "          [-1.3273e-01, -1.2578e+00, -1.4778e-01,  ..., -1.4736e+00,\n",
            "           -1.2301e+00,  3.8196e-01],\n",
            "          [ 8.6390e-02,  2.0893e+00,  1.5113e+00,  ...,  3.9336e-01,\n",
            "            4.3661e-01, -1.6221e-01],\n",
            "          [-1.3816e+00,  6.9628e-01,  6.9676e-02,  ...,  1.7014e+00,\n",
            "            1.9847e+00,  1.1700e-01]],\n",
            "\n",
            "         [[-1.1477e-01, -2.5245e+00, -2.0078e+00,  ...,  7.0241e-01,\n",
            "           -7.2753e-01, -3.2443e-01],\n",
            "          [ 1.7326e+00,  7.5553e-01, -8.4078e-01,  ..., -2.3335e-01,\n",
            "            5.0567e-02,  6.4500e-01],\n",
            "          [ 1.0077e+00, -5.1003e-01,  5.8932e-01,  ...,  3.5859e-01,\n",
            "            7.1952e-01, -8.7702e-02],\n",
            "          ...,\n",
            "          [-3.3930e-01,  3.1171e-01,  9.9772e-02,  ..., -2.0443e+00,\n",
            "            3.6271e-01, -9.5282e-01],\n",
            "          [-8.7686e-01, -2.1331e-01, -5.6254e-03,  ..., -4.8063e-01,\n",
            "            3.7580e-01,  1.3395e+00],\n",
            "          [-1.6500e+00, -3.9507e-02,  4.2681e-01,  ...,  1.2121e-01,\n",
            "           -2.0188e-01, -6.4053e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.7922e-01, -6.9920e-01,  5.8835e-01,  ..., -9.5465e-01,\n",
            "            4.2383e-01,  1.9464e+00],\n",
            "          [ 9.9090e-01, -4.3438e-01, -8.7781e-02,  ...,  2.2985e-01,\n",
            "            2.0530e-01, -1.3001e+00],\n",
            "          [-1.0331e+00, -2.8627e-01, -8.9134e-02,  ..., -2.1168e+00,\n",
            "            5.3516e-01,  5.5588e-01],\n",
            "          ...,\n",
            "          [-5.3714e-01,  1.2600e+00,  1.5738e+00,  ..., -4.8851e-01,\n",
            "           -9.9394e-02,  3.9455e-01],\n",
            "          [-1.4464e+00, -7.6559e-01, -1.0369e+00,  ...,  8.4901e-01,\n",
            "           -1.6877e+00,  4.6206e-02],\n",
            "          [ 8.2118e-01, -3.7398e-01,  1.7210e+00,  ...,  7.0041e-01,\n",
            "           -1.4383e+00, -1.4638e+00]],\n",
            "\n",
            "         [[ 4.8835e-01, -1.6608e+00, -1.4276e+00,  ...,  1.3022e+00,\n",
            "            5.1704e-01,  4.0896e-01],\n",
            "          [ 1.4597e+00,  1.2317e+00, -7.2338e-01,  ..., -1.2138e+00,\n",
            "            4.8013e-01, -7.1109e-01],\n",
            "          [ 2.8373e-01,  2.3457e+00, -1.2915e+00,  ..., -8.5280e-01,\n",
            "            1.5031e-01, -8.7154e-02],\n",
            "          ...,\n",
            "          [-5.8753e-02, -1.2711e-01,  3.6749e-01,  ...,  6.6114e-01,\n",
            "           -8.3500e-01, -1.9306e-01],\n",
            "          [ 1.4228e+00, -6.6266e-01,  1.6746e+00,  ...,  5.9620e-01,\n",
            "            6.0373e-01, -1.1971e+00],\n",
            "          [ 1.2953e+00, -3.4986e-02, -1.6957e+00,  ..., -2.6945e-01,\n",
            "           -8.1868e-01,  1.5272e-01]],\n",
            "\n",
            "         [[-7.2360e-01,  2.2379e-01,  2.8016e-02,  ..., -1.4946e+00,\n",
            "            1.0160e+00, -9.9444e-03],\n",
            "          [-3.5347e-01, -5.5275e-01, -5.1600e-01,  ...,  4.8443e-01,\n",
            "           -1.5924e+00,  2.3182e-01],\n",
            "          [ 7.6660e-01, -1.1507e+00,  2.1143e+00,  ..., -6.1880e-01,\n",
            "           -8.0766e-01,  9.6654e-01],\n",
            "          ...,\n",
            "          [-4.0869e-01, -1.0598e+00, -1.2292e+00,  ...,  1.1217e+00,\n",
            "            7.2120e-01,  1.8157e+00],\n",
            "          [-9.0249e-01,  8.3441e-01, -1.1926e+00,  ...,  1.9790e+00,\n",
            "            1.3256e+00,  1.3332e+00],\n",
            "          [ 3.7180e-01, -1.1237e+00, -7.9998e-01,  ..., -1.4325e-01,\n",
            "           -3.2711e-01, -6.4454e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.7461e-01, -5.4535e-01,  1.7495e+00,  ...,  4.6208e-01,\n",
            "           -6.5809e-01,  1.1329e+00],\n",
            "          [ 1.6733e+00,  1.1227e+00,  4.7839e-01,  ..., -1.5421e-01,\n",
            "           -2.7449e-03, -7.5994e-01],\n",
            "          [ 4.6674e-01, -1.4024e+00,  6.4959e-01,  ...,  1.8995e+00,\n",
            "           -9.6039e-01, -3.0464e-01],\n",
            "          ...,\n",
            "          [-1.9605e+00, -3.1951e-01, -3.9531e-01,  ...,  1.4555e+00,\n",
            "            7.4372e-01,  9.4143e-02],\n",
            "          [ 2.3745e-01,  9.8021e-01,  9.4668e-02,  ...,  7.3879e-01,\n",
            "           -5.1170e-03,  1.4300e+00],\n",
            "          [ 1.3937e+00, -1.4714e-01,  1.5990e+00,  ..., -3.9997e-01,\n",
            "            3.3939e-02, -5.5419e-01]],\n",
            "\n",
            "         [[-1.0631e+00, -4.1282e-01, -7.7668e-01,  ...,  4.3933e-01,\n",
            "           -1.0306e+00, -5.2813e-01],\n",
            "          [-1.2445e+00, -8.1694e-01,  5.3931e-01,  ..., -2.8105e-01,\n",
            "           -1.3356e-01,  5.8515e-01],\n",
            "          [-2.5922e-01, -1.2575e+00,  2.7017e+00,  ...,  2.9264e-02,\n",
            "            1.0766e+00,  1.1265e+00],\n",
            "          ...,\n",
            "          [-2.8960e-01,  2.7916e-01,  7.2930e-01,  ...,  2.8818e-01,\n",
            "           -5.8704e-01, -1.3446e+00],\n",
            "          [ 8.1711e-01, -7.7254e-01, -7.1791e-01,  ...,  6.2750e-01,\n",
            "            1.1469e+00,  4.6975e-01],\n",
            "          [-3.4732e-01,  1.1047e+00,  9.9736e-01,  ...,  1.7201e-01,\n",
            "           -5.4645e-01,  1.5456e+00]],\n",
            "\n",
            "         [[-7.9021e-01, -1.2640e+00,  1.6979e+00,  ..., -2.7907e-01,\n",
            "            7.0597e-01, -1.8189e+00],\n",
            "          [-7.0180e-01, -2.6322e-01, -1.5182e+00,  ...,  1.0563e+00,\n",
            "            1.7313e-01, -2.0886e-01],\n",
            "          [ 7.8114e-01, -6.2083e-01,  6.0636e-02,  ..., -8.8752e-01,\n",
            "            8.0124e-01, -1.8670e-01],\n",
            "          ...,\n",
            "          [ 1.7247e+00,  1.5950e+00, -1.2489e+00,  ...,  2.5830e-01,\n",
            "           -8.2142e-01, -1.4374e+00],\n",
            "          [-3.0480e-01,  2.8047e-02, -8.5425e-01,  ..., -5.5101e-01,\n",
            "           -3.0468e-01,  2.3358e-01],\n",
            "          [-7.4174e-02, -6.4208e-01,  1.9849e+00,  ..., -9.3178e-01,\n",
            "           -4.1183e-01,  2.2388e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.4470e-01, -1.5370e+00, -1.6167e+00,  ..., -8.9963e-01,\n",
            "           -4.2539e-01,  1.3319e+00],\n",
            "          [-2.2979e+00,  6.0316e-01, -8.3901e-01,  ...,  1.2997e+00,\n",
            "            1.0459e+00,  2.6385e-01],\n",
            "          [ 6.2352e-01, -1.0026e+00,  1.5185e+00,  ..., -7.1834e-01,\n",
            "           -2.1928e-01,  2.9497e-01],\n",
            "          ...,\n",
            "          [ 3.3143e-01, -3.7660e-01, -3.0524e-01,  ..., -6.3391e-01,\n",
            "           -5.5494e-01,  1.2416e+00],\n",
            "          [-1.6843e+00, -4.8225e-01,  1.2273e+00,  ...,  1.5052e+00,\n",
            "            2.0376e+00,  1.3372e+00],\n",
            "          [-1.4434e+00,  4.9648e-01, -1.4930e-01,  ...,  1.7700e+00,\n",
            "           -7.0490e-01,  4.2878e-02]],\n",
            "\n",
            "         [[ 3.2619e-01, -7.9291e-02, -1.8359e-01,  ..., -1.4560e-01,\n",
            "            6.2983e-02,  9.9125e-02],\n",
            "          [ 5.3299e-01, -6.7532e-01, -1.3987e-01,  ...,  1.5668e+00,\n",
            "           -1.0806e+00, -2.3545e-01],\n",
            "          [ 3.8376e-01, -5.6270e-01, -1.1236e+00,  ...,  8.9986e-02,\n",
            "           -4.9133e-03,  4.2046e-01],\n",
            "          ...,\n",
            "          [-1.9506e+00, -1.1946e+00, -6.3365e-01,  ...,  1.7767e+00,\n",
            "           -1.4954e-01,  5.3420e-01],\n",
            "          [-4.6398e-01,  2.6881e+00,  1.1614e+00,  ..., -1.6009e-01,\n",
            "            3.4809e-01,  1.4329e-01],\n",
            "          [ 4.0075e-02,  4.2815e-01, -1.3681e+00,  ..., -1.6381e+00,\n",
            "            6.3382e-02,  7.3436e-01]],\n",
            "\n",
            "         [[ 1.7544e+00, -8.1410e-01,  4.5288e-01,  ...,  6.9309e-01,\n",
            "           -5.3357e-02, -1.0935e+00],\n",
            "          [ 1.5470e-01, -7.3314e-01, -4.7735e-01,  ...,  3.8258e-01,\n",
            "           -1.5806e-01,  6.2899e-01],\n",
            "          [-1.0669e+00,  2.1606e+00, -5.2389e-01,  ..., -5.7815e-01,\n",
            "           -7.3478e-01, -6.8431e-02],\n",
            "          ...,\n",
            "          [ 2.1654e-01,  1.8255e+00, -2.1905e-01,  ..., -1.0812e+00,\n",
            "            6.7870e-01,  3.8282e-01],\n",
            "          [-2.9108e-02,  7.2502e-02,  5.9899e-03,  ..., -6.3782e-02,\n",
            "           -3.4725e-02, -2.3256e-01],\n",
            "          [-3.5376e-01, -8.7611e-01,  2.4843e-01,  ..., -2.0393e+00,\n",
            "           -7.6397e-02,  1.2284e+00]]],\n",
            "\n",
            "\n",
            "        [[[-1.7347e+00,  1.0578e-02, -8.6876e-01,  ..., -2.3324e-01,\n",
            "            2.8250e-01, -8.0911e-01],\n",
            "          [ 9.4357e-01, -3.2217e-01, -2.8498e-04,  ..., -5.8380e-02,\n",
            "           -4.8644e-01,  1.2516e+00],\n",
            "          [-4.5300e-02, -1.9691e+00,  9.6795e-01,  ..., -3.5484e+00,\n",
            "           -4.7028e-01,  1.3365e+00],\n",
            "          ...,\n",
            "          [-1.0610e+00,  8.4595e-02,  1.5223e+00,  ...,  1.4337e+00,\n",
            "            1.6758e+00,  1.1447e+00],\n",
            "          [ 6.5615e-01,  9.5722e-01, -6.2111e-01,  ..., -3.4415e-01,\n",
            "            8.8856e-01, -7.4179e-01],\n",
            "          [-1.1294e+00, -2.2476e-01,  5.2923e-01,  ..., -2.8648e-01,\n",
            "            5.8157e-01,  9.4557e-01]],\n",
            "\n",
            "         [[ 1.1424e+00,  1.2151e+00,  8.2054e-02,  ...,  1.7269e+00,\n",
            "            1.0425e+00,  3.0102e-01],\n",
            "          [ 9.8280e-03, -8.8188e-01, -9.3365e-01,  ..., -1.2722e+00,\n",
            "            4.7630e-01,  1.3798e+00],\n",
            "          [ 9.4052e-01,  8.8818e-01, -1.1258e+00,  ..., -5.7566e-01,\n",
            "            3.6314e+00, -1.1147e+00],\n",
            "          ...,\n",
            "          [-7.5544e-02,  2.9685e-01,  1.3821e+00,  ...,  1.3681e-02,\n",
            "            3.4440e-01,  2.3225e-01],\n",
            "          [-1.0916e+00,  1.1010e+00,  4.7866e-01,  ...,  6.2367e-01,\n",
            "           -1.8163e-01, -9.5669e-01],\n",
            "          [-1.2591e+00,  3.3689e-01, -3.5528e-01,  ..., -8.6529e-01,\n",
            "            4.5887e-01,  7.5615e-01]],\n",
            "\n",
            "         [[ 1.5610e+00,  3.9859e-01, -2.9509e-01,  ...,  1.0375e+00,\n",
            "           -1.2874e+00, -4.6880e-01],\n",
            "          [-2.2926e+00, -1.3156e+00, -2.6161e-01,  ..., -6.4265e-02,\n",
            "           -1.3487e+00, -4.4951e-01],\n",
            "          [-1.5865e+00,  2.4938e-01,  4.5908e-01,  ...,  2.4580e-01,\n",
            "            1.0267e+00,  1.4655e+00],\n",
            "          ...,\n",
            "          [ 1.4719e+00, -1.8091e+00,  1.1560e+00,  ..., -1.8392e-01,\n",
            "            1.2412e-02,  1.2073e+00],\n",
            "          [-8.4376e-01, -1.5965e-01,  6.0831e-02,  ..., -7.9663e-01,\n",
            "           -2.9450e-01, -3.8134e-01],\n",
            "          [-5.9385e-03, -9.1283e-01,  1.8339e+00,  ..., -1.9805e+00,\n",
            "           -6.5101e-01,  9.0359e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0635e+00, -7.8113e-01,  1.3536e+00,  ..., -1.9906e-01,\n",
            "            1.9788e-01, -2.5209e+00],\n",
            "          [-4.9573e-01,  1.5486e+00, -1.9534e-01,  ..., -2.1185e+00,\n",
            "           -1.2145e+00, -5.9887e-01],\n",
            "          [ 4.9184e-02, -1.4703e+00,  7.3258e-01,  ...,  4.9062e-01,\n",
            "           -1.1767e+00,  5.5692e-01],\n",
            "          ...,\n",
            "          [ 7.9125e-01, -1.2898e-01, -1.2832e+00,  ..., -2.1768e-02,\n",
            "            1.1102e+00,  2.5234e+00],\n",
            "          [ 3.5304e-01,  4.5454e-01,  8.5626e-01,  ..., -1.3705e+00,\n",
            "            1.8297e-01,  3.8873e+00],\n",
            "          [-5.2888e-01, -8.0065e-01,  2.9700e-01,  ...,  1.7744e+00,\n",
            "           -2.4914e+00,  1.0648e+00]],\n",
            "\n",
            "         [[-3.6347e-01,  9.0428e-01,  1.0571e+00,  ...,  1.3937e-01,\n",
            "           -1.5705e+00,  1.4221e+00],\n",
            "          [-1.2319e+00,  1.1822e+00,  8.2660e-01,  ...,  6.5856e-01,\n",
            "           -6.5505e-01, -3.6674e-01],\n",
            "          [-1.5276e+00, -7.2951e-01, -1.2815e+00,  ..., -8.9145e-01,\n",
            "            9.2285e-01,  4.4646e-01],\n",
            "          ...,\n",
            "          [-5.3128e-01, -6.5534e-02,  8.0512e-01,  ..., -1.9622e-01,\n",
            "            3.1000e-01,  3.6108e-01],\n",
            "          [-2.2892e-01, -5.5612e-01, -5.3451e-01,  ...,  1.1544e+00,\n",
            "           -1.2369e+00,  6.2857e-01],\n",
            "          [-1.7028e+00,  5.7754e-01, -1.3850e+00,  ..., -1.9171e+00,\n",
            "            1.6377e+00,  1.6040e-01]],\n",
            "\n",
            "         [[ 2.7713e-01, -1.0196e+00,  1.8616e+00,  ...,  8.2033e-01,\n",
            "            9.0866e-01,  1.5219e+00],\n",
            "          [-6.4007e-01,  5.2923e-01,  2.4388e-01,  ...,  1.9991e-01,\n",
            "            4.2957e-01, -1.7984e+00],\n",
            "          [-9.5856e-01,  1.6559e+00, -4.0193e-01,  ..., -2.4293e-01,\n",
            "           -1.2989e+00,  1.3883e-01],\n",
            "          ...,\n",
            "          [-2.1903e-01, -4.7872e-01,  1.8965e-01,  ..., -3.2603e-02,\n",
            "           -2.0675e-01,  1.4377e-01],\n",
            "          [-1.4601e-01,  1.2180e+00,  7.8088e-01,  ...,  8.7294e-01,\n",
            "           -4.7251e-01, -1.3313e+00],\n",
            "          [ 1.4139e+00, -6.5648e-01, -2.5133e-03,  ..., -1.2370e+00,\n",
            "           -9.7553e-01, -2.8467e-01]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5hKfTuqjzMH",
        "outputId": "abae21e9-c279-41e4-cac7-829be43c60e5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 2.8164e-01,  3.0153e-01, -2.1470e-01,  ..., -2.3871e-01,\n",
            "           -4.9434e-02,  1.7891e-01],\n",
            "          [-5.1352e-02,  1.9733e-01,  8.5379e-02,  ..., -4.2392e-01,\n",
            "            2.0829e-01, -3.4818e-01],\n",
            "          [ 3.8206e-02, -5.9666e-01, -3.3613e-01,  ...,  7.7325e-01,\n",
            "           -1.1029e+00, -5.2057e-01],\n",
            "          ...,\n",
            "          [-2.9364e-01, -3.3975e-01, -1.2422e+00,  ...,  1.8691e-01,\n",
            "            7.3179e-01, -2.4129e-01],\n",
            "          [ 4.8829e-01, -4.4545e-01, -7.4387e-02,  ...,  4.6584e-01,\n",
            "            5.8498e-02,  9.1343e-01],\n",
            "          [-3.9437e-01, -3.4448e-01,  2.4943e-01,  ...,  2.8179e-02,\n",
            "           -4.5648e-01,  4.0351e-01]],\n",
            "\n",
            "         [[-1.6179e-02, -4.8893e-02, -4.7010e-01,  ...,  4.2170e-01,\n",
            "            1.5907e-01,  8.8589e-02],\n",
            "          [-7.3067e-01,  3.4039e-01, -3.4916e-01,  ..., -1.7737e-01,\n",
            "           -8.9603e-02, -3.5957e-02],\n",
            "          [ 1.2194e-01, -9.3438e-01,  9.5640e-02,  ..., -2.7312e-01,\n",
            "           -1.9887e-01,  2.9446e-02],\n",
            "          ...,\n",
            "          [-3.6068e-01, -3.6487e-01, -1.3110e+00,  ...,  4.1965e-01,\n",
            "           -7.4297e-01,  6.9126e-01],\n",
            "          [-1.6987e-01, -1.5224e-01, -1.4905e-01,  ...,  7.1103e-01,\n",
            "           -5.5663e-01,  7.7183e-01],\n",
            "          [ 9.4585e-03,  3.8530e-01,  4.8336e-01,  ...,  1.2635e-01,\n",
            "            6.9247e-01, -1.1968e+00]],\n",
            "\n",
            "         [[-2.6403e-01, -2.3915e-01, -2.1832e-01,  ..., -9.0551e-02,\n",
            "            2.6838e-01,  5.2104e-01],\n",
            "          [-1.4042e-01,  3.2069e-01, -7.8465e-01,  ...,  3.2379e-01,\n",
            "            2.3012e-02, -1.5017e-01],\n",
            "          [-5.1742e-01, -1.9045e-01, -3.8390e-01,  ...,  1.4669e+00,\n",
            "           -5.4375e-01, -2.9308e-01],\n",
            "          ...,\n",
            "          [ 8.6746e-01, -2.3979e-01, -2.7221e-01,  ...,  7.0624e-02,\n",
            "           -1.1160e-01, -3.0395e-01],\n",
            "          [-1.5191e-01, -1.3264e-01,  4.8144e-01,  ..., -1.0511e+00,\n",
            "           -1.0421e+00, -2.7941e-01],\n",
            "          [ 8.8844e-02, -3.1310e-01, -4.0045e-01,  ..., -1.9534e-02,\n",
            "            1.2187e-01, -5.6598e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.5582e-01, -2.7242e-01,  2.2440e-01,  ...,  2.9421e-03,\n",
            "            9.3822e-03, -1.5746e-01],\n",
            "          [-2.0401e-01,  5.1393e-01,  6.7405e-02,  ...,  5.2143e-01,\n",
            "            1.5233e-01, -9.0336e-01],\n",
            "          [-7.8982e-01, -1.1741e-01,  7.5086e-01,  ..., -7.1288e-01,\n",
            "            2.0049e-01,  1.9992e-01],\n",
            "          ...,\n",
            "          [ 7.0037e-01,  4.7747e-02, -2.7865e-01,  ..., -3.9436e-01,\n",
            "            2.8827e-01, -1.9448e-01],\n",
            "          [ 6.3823e-02,  1.1308e-01,  1.1230e-01,  ..., -2.0869e-01,\n",
            "           -1.3682e-02,  5.2703e-01],\n",
            "          [-4.2802e-01, -1.2483e+00,  2.1409e-01,  ...,  4.2584e-01,\n",
            "            3.8202e-01,  3.2445e-01]],\n",
            "\n",
            "         [[ 3.2284e-04,  4.3796e-02, -7.3124e-02,  ...,  2.8766e-01,\n",
            "           -3.4887e-01,  4.7918e-01],\n",
            "          [-3.6366e-01, -5.1033e-01,  8.9767e-01,  ...,  1.3031e-01,\n",
            "            3.4298e-01,  1.7823e-01],\n",
            "          [ 5.8009e-01,  7.8052e-01,  7.1198e-02,  ...,  2.3848e-01,\n",
            "           -1.7493e-01, -5.1876e-01],\n",
            "          ...,\n",
            "          [-2.6132e-02,  4.0318e-01, -2.6903e-01,  ..., -6.0488e-01,\n",
            "            1.4175e-01, -8.8535e-01],\n",
            "          [-1.5984e-01,  5.5822e-01,  1.8372e-01,  ..., -1.0520e-01,\n",
            "            2.1707e-01,  4.1425e-01],\n",
            "          [ 3.0501e-01, -6.7240e-02, -6.4010e-01,  ...,  3.4033e-01,\n",
            "           -3.2990e-01,  3.6246e-01]],\n",
            "\n",
            "         [[ 4.0884e-01, -2.2630e-01,  5.9874e-01,  ..., -4.2593e-01,\n",
            "           -5.9472e-01, -1.5017e-01],\n",
            "          [-1.8376e-01,  6.3182e-01, -5.5225e-01,  ...,  4.1410e-01,\n",
            "           -4.3819e-02, -3.1562e-01],\n",
            "          [ 1.0530e-01, -4.1464e-01,  5.8414e-01,  ...,  3.7302e-01,\n",
            "           -1.1321e-01,  6.7819e-01],\n",
            "          ...,\n",
            "          [ 7.9668e-03, -8.0400e-01,  1.5826e+00,  ...,  6.7457e-02,\n",
            "            1.1792e-02, -3.1359e-01],\n",
            "          [ 3.1936e-01,  4.7804e-02,  1.3414e-01,  ...,  5.8474e-01,\n",
            "           -2.6621e-01,  4.3498e-01],\n",
            "          [-6.2161e-01, -1.5274e-01,  9.0571e-02,  ...,  6.3991e-01,\n",
            "           -4.0136e-02,  2.6260e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1977e-01,  5.7638e-02,  5.8318e-01,  ...,  2.7033e-01,\n",
            "            1.5626e-01, -1.1916e-01],\n",
            "          [ 1.1187e-01,  1.1274e-01,  1.3367e-01,  ...,  2.5694e-01,\n",
            "            5.1704e-01,  3.1418e-01],\n",
            "          [-1.8698e-01,  3.6692e-01,  4.2460e-01,  ...,  2.7902e-01,\n",
            "           -2.5447e-01,  5.0161e-01],\n",
            "          ...,\n",
            "          [-7.2952e-01, -1.0846e+00,  1.3434e+00,  ...,  2.5026e-01,\n",
            "            5.6226e-01, -8.9350e-01],\n",
            "          [ 4.3544e-01, -5.7036e-02,  9.1648e-01,  ...,  8.9147e-01,\n",
            "           -5.4310e-01,  2.1926e-01],\n",
            "          [-2.1446e-02,  5.5549e-01,  3.5955e-01,  ...,  2.2546e-01,\n",
            "           -5.0745e-01, -2.7707e-01]],\n",
            "\n",
            "         [[-4.2315e-01,  3.0418e-03,  3.7686e-02,  ...,  4.8607e-01,\n",
            "            1.5996e-02,  4.6770e-02],\n",
            "          [-2.7465e-01,  2.8113e-01,  4.4494e-01,  ..., -2.5468e-01,\n",
            "           -1.2659e-02,  1.6582e-01],\n",
            "          [ 2.9009e-01,  4.9072e-01,  2.9344e-01,  ...,  5.2728e-01,\n",
            "           -3.6748e-01,  3.0729e-01],\n",
            "          ...,\n",
            "          [ 9.2278e-02, -1.2582e-01, -6.5793e-01,  ..., -5.6571e-01,\n",
            "            8.8092e-01,  2.1752e-01],\n",
            "          [ 1.7685e-01,  2.5848e-01,  3.1399e-01,  ...,  4.0091e-01,\n",
            "            1.6147e-01, -4.2175e-01],\n",
            "          [ 4.4492e-01, -4.5452e-01,  2.0159e-01,  ...,  4.0015e-01,\n",
            "           -9.9972e-02, -2.7942e-01]],\n",
            "\n",
            "         [[ 5.9159e-02, -1.1856e-01, -3.5138e-01,  ..., -3.1703e-01,\n",
            "            3.6136e-01,  1.4159e-01],\n",
            "          [-3.1293e-01,  6.7808e-01, -1.3560e+00,  ..., -2.0073e-01,\n",
            "            2.8199e-01, -9.4196e-01],\n",
            "          [ 2.5711e-01,  6.8002e-02,  8.0943e-01,  ..., -1.0735e+00,\n",
            "            1.4815e-01, -6.8351e-01],\n",
            "          ...,\n",
            "          [-1.9359e-01, -4.8247e-01, -3.1575e-01,  ..., -1.0358e+00,\n",
            "            1.9240e-01, -4.1804e-01],\n",
            "          [-3.6667e-02,  5.5611e-02,  1.2119e+00,  ...,  5.7768e-03,\n",
            "           -1.8550e-01, -1.4164e-01],\n",
            "          [-3.5876e-01, -1.5630e-01,  3.4142e-01,  ..., -2.5673e-01,\n",
            "            1.4223e-01, -1.3395e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.9035e-01, -2.3076e-02, -5.4355e-01,  ...,  1.1201e-01,\n",
            "           -1.4629e-02,  1.5764e-01],\n",
            "          [-8.2978e-02, -6.2044e-01, -5.7138e-01,  ..., -4.4683e-01,\n",
            "           -1.6903e-01, -1.8497e-02],\n",
            "          [-6.5549e-02,  4.9851e-01,  1.4937e-01,  ..., -4.5329e-01,\n",
            "            1.0535e+00, -9.9000e-02],\n",
            "          ...,\n",
            "          [-2.9818e-02, -6.7192e-01,  1.8167e-01,  ..., -6.0735e-01,\n",
            "           -1.7403e-01, -1.6717e-01],\n",
            "          [-1.4600e-01, -4.8535e-01,  1.7767e-01,  ..., -4.2307e-02,\n",
            "            1.6533e-01,  6.3783e-01],\n",
            "          [ 1.5740e-01, -9.9965e-01,  6.8106e-01,  ..., -3.6342e-01,\n",
            "            6.8981e-01,  2.3550e-01]],\n",
            "\n",
            "         [[ 5.1623e-02,  7.0218e-01,  1.0175e-02,  ..., -9.6625e-02,\n",
            "            5.9419e-02, -1.0814e-01],\n",
            "          [ 5.0951e-01,  2.5352e-02, -3.0955e-01,  ...,  5.2349e-01,\n",
            "            4.0604e-01, -1.3850e-01],\n",
            "          [ 4.6395e-02, -4.5806e-01,  8.2585e-01,  ...,  2.9250e-01,\n",
            "            2.3495e-01, -3.4856e-01],\n",
            "          ...,\n",
            "          [-4.8045e-01,  1.1592e-01,  1.3976e+00,  ..., -1.6788e-01,\n",
            "            6.8724e-01,  4.8187e-01],\n",
            "          [ 4.1436e-01,  2.1718e-01,  3.1626e-01,  ...,  2.8217e-02,\n",
            "           -1.2927e-01,  2.8482e-02],\n",
            "          [ 4.7450e-01,  1.1035e-01,  7.7897e-02,  ..., -4.6077e-01,\n",
            "            2.4858e-01, -2.5383e-01]],\n",
            "\n",
            "         [[ 1.5417e-01,  4.2055e-01, -3.0280e-01,  ...,  3.1587e-01,\n",
            "           -2.2539e-01, -2.0325e-01],\n",
            "          [ 5.4816e-01,  1.0228e-01,  3.6836e-02,  ..., -2.5968e-01,\n",
            "           -3.9307e-01,  5.9874e-01],\n",
            "          [-4.7804e-01,  2.9072e-01, -8.4559e-01,  ...,  6.2011e-01,\n",
            "           -3.4514e-02,  6.9140e-01],\n",
            "          ...,\n",
            "          [-1.2624e-01, -5.6834e-01,  7.6856e-02,  ...,  1.2821e+00,\n",
            "            6.0954e-03, -2.1617e-02],\n",
            "          [ 4.2612e-01,  9.2113e-01,  4.5543e-01,  ..., -1.0229e-01,\n",
            "           -1.4506e-01, -1.0773e-01],\n",
            "          [-4.3886e-01, -6.3114e-01, -1.1781e-01,  ...,  8.9408e-01,\n",
            "           -2.6939e-01,  7.6411e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.0289e-01, -2.9547e-01, -7.3816e-03,  ..., -2.7929e-01,\n",
            "            4.3418e-01,  1.7322e-01],\n",
            "          [ 1.6528e-01, -4.7176e-01, -6.6694e-01,  ..., -2.7246e-01,\n",
            "           -6.5881e-01,  7.1052e-01],\n",
            "          [ 3.1155e-01, -3.5168e-01,  2.9108e-01,  ...,  6.6425e-01,\n",
            "            3.9004e-01, -8.3597e-01],\n",
            "          ...,\n",
            "          [-4.3998e-01, -3.5488e-01,  5.6205e-01,  ...,  4.5686e-01,\n",
            "            7.1669e-01,  5.8650e-02],\n",
            "          [ 2.5419e-01,  3.3798e-01,  5.0293e-01,  ..., -2.0227e-01,\n",
            "            2.5310e-01, -7.3458e-01],\n",
            "          [ 1.6072e-01,  5.3257e-01,  2.7021e-02,  ...,  6.0434e-01,\n",
            "            2.8743e-01,  6.2041e-01]],\n",
            "\n",
            "         [[ 3.7611e-02, -2.2076e-01, -1.8602e-02,  ..., -1.2771e-01,\n",
            "            1.0198e-01, -1.7427e-01],\n",
            "          [-5.7917e-01, -1.6592e-01,  8.3188e-01,  ...,  1.1446e-01,\n",
            "            1.6316e-01,  4.7673e-01],\n",
            "          [-6.4669e-02, -1.0798e+00,  3.9431e-01,  ...,  4.5350e-01,\n",
            "           -1.2377e-02,  2.2619e-01],\n",
            "          ...,\n",
            "          [ 6.5934e-01, -3.4796e-01,  7.1807e-02,  ...,  1.6789e+00,\n",
            "           -2.2196e-01, -2.2394e-01],\n",
            "          [ 2.4189e-01,  1.1755e-01,  4.6554e-01,  ...,  8.1592e-02,\n",
            "            3.7790e-01,  1.2692e-01],\n",
            "          [ 2.9979e-01,  3.6566e-01, -8.2293e-01,  ..., -7.7847e-02,\n",
            "           -2.7677e-01,  4.9581e-01]],\n",
            "\n",
            "         [[ 1.6923e-01, -3.5785e-01, -4.2178e-01,  ...,  5.1790e-01,\n",
            "           -2.6299e-02, -4.1178e-02],\n",
            "          [-1.0853e+00, -4.2448e-01, -1.5188e-02,  ..., -1.7945e-01,\n",
            "            1.2705e+00,  3.1241e-01],\n",
            "          [-3.0731e-01, -4.5193e-01,  4.3658e-01,  ..., -1.2755e-01,\n",
            "           -1.0685e-01,  5.9053e-01],\n",
            "          ...,\n",
            "          [-8.6736e-01,  4.4266e-01,  8.5033e-01,  ...,  1.4263e-01,\n",
            "            6.3784e-01,  2.6245e-01],\n",
            "          [-3.1291e-01, -9.1188e-01,  1.5280e-01,  ...,  8.2013e-01,\n",
            "           -6.2791e-01, -4.3316e-01],\n",
            "          [ 8.4752e-02, -1.9573e-01, -3.1220e-01,  ...,  1.0223e-01,\n",
            "           -2.0253e-01,  3.8355e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.2718e-01,  6.0966e-02, -1.9066e-01,  ...,  1.0677e-01,\n",
            "            2.3994e-01,  4.7158e-03],\n",
            "          [-4.1765e-01, -4.0011e-01, -1.9836e-01,  ..., -5.5739e-01,\n",
            "            4.3788e-01, -2.0188e-01],\n",
            "          [-1.2130e+00, -7.2100e-02, -4.4685e-02,  ...,  3.7709e-01,\n",
            "           -6.3816e-01,  1.3703e-01],\n",
            "          ...,\n",
            "          [-5.6581e-02, -2.7198e-01,  6.4224e-02,  ...,  2.4811e-01,\n",
            "           -7.1361e-01, -2.3108e-02],\n",
            "          [ 1.4887e-01,  3.8478e-01,  1.9890e-02,  ..., -2.4430e-01,\n",
            "           -2.3173e-01,  1.3224e-01],\n",
            "          [-1.2216e-01,  5.2719e-02, -5.9341e-01,  ...,  7.7128e-01,\n",
            "            2.1605e-01, -2.3498e-01]],\n",
            "\n",
            "         [[ 4.2157e-01, -7.3784e-01,  1.1937e-01,  ..., -1.0537e-01,\n",
            "            8.1099e-01, -1.6492e-01],\n",
            "          [ 6.3182e-02, -6.2540e-01,  1.9354e-01,  ..., -5.5644e-01,\n",
            "           -5.1465e-01, -2.5785e-01],\n",
            "          [-1.8639e-01, -4.6023e-01, -3.5687e-01,  ..., -1.0083e-01,\n",
            "           -5.7827e-02, -4.9151e-02],\n",
            "          ...,\n",
            "          [-3.4306e-01, -2.4809e-01, -3.5161e-01,  ...,  5.6524e-01,\n",
            "            8.2454e-02,  1.4442e-01],\n",
            "          [-2.1441e-01,  3.9470e-01,  4.2619e-02,  ..., -1.7562e-01,\n",
            "            4.8993e-01,  9.2174e-02],\n",
            "          [ 3.3400e-01, -6.3946e-02,  1.0322e-01,  ..., -4.7729e-01,\n",
            "            1.4299e-01, -4.3450e-01]],\n",
            "\n",
            "         [[ 2.5253e-02,  1.3185e-01, -6.6716e-02,  ...,  6.6641e-01,\n",
            "            3.6942e-01,  3.1626e-03],\n",
            "          [-1.9364e-01, -1.2526e-01, -6.1183e-01,  ...,  2.6413e-01,\n",
            "           -6.0517e-01, -7.9545e-01],\n",
            "          [-3.8960e-01,  2.6653e-01,  3.9553e-01,  ...,  7.3249e-01,\n",
            "            4.5494e-01,  1.6099e-01],\n",
            "          ...,\n",
            "          [-1.8869e-01,  1.7558e-01,  4.4220e-01,  ..., -8.0800e-01,\n",
            "           -8.6617e-01, -6.0688e-01],\n",
            "          [ 3.0576e-01,  3.4964e-01, -6.2778e-01,  ..., -1.0090e-01,\n",
            "            2.4543e-01,  2.3543e-01],\n",
            "          [-1.6295e-02, -2.7877e-01,  6.6782e-01,  ...,  1.5021e-01,\n",
            "           -1.7138e-01, -2.0745e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.3837e-01, -3.3001e-01, -4.6050e-01,  ...,  5.4548e-02,\n",
            "            1.9444e-01, -1.5431e-01],\n",
            "          [-2.9402e-01,  3.6167e-01, -7.9886e-02,  ..., -7.5483e-01,\n",
            "           -1.8704e-01,  1.0300e-02],\n",
            "          [-2.0861e-01,  7.6480e-01,  7.2264e-01,  ...,  7.6254e-01,\n",
            "            1.0678e-01,  1.1853e+00],\n",
            "          ...,\n",
            "          [ 4.2294e-01, -8.5963e-01,  6.8934e-01,  ..., -2.0029e-01,\n",
            "           -2.5026e-01, -4.1439e-01],\n",
            "          [ 1.1511e-01,  2.8255e-02, -2.0289e-01,  ...,  8.1301e-01,\n",
            "           -1.9189e-01, -3.1629e-01],\n",
            "          [ 6.4498e-02,  2.7042e-01,  4.3017e-01,  ...,  6.3025e-01,\n",
            "            4.2467e-01,  2.7700e-01]],\n",
            "\n",
            "         [[ 1.6214e-01, -3.4305e-01, -9.6559e-02,  ...,  4.7758e-01,\n",
            "           -7.3354e-02, -4.8387e-02],\n",
            "          [-2.7392e-01, -6.0639e-01,  3.3913e-01,  ..., -3.2625e-01,\n",
            "            3.0035e-02, -5.7690e-01],\n",
            "          [ 3.4357e-01, -4.9771e-01,  7.6250e-01,  ...,  3.7921e-01,\n",
            "           -3.6112e-01, -1.6037e-01],\n",
            "          ...,\n",
            "          [-5.0154e-01,  5.3269e-01,  5.8160e-01,  ...,  1.0089e-01,\n",
            "           -2.8210e-01,  9.9556e-01],\n",
            "          [ 3.0776e-01, -1.4983e-02, -5.3176e-01,  ..., -7.5945e-01,\n",
            "            3.3448e-01,  4.2717e-01],\n",
            "          [ 6.2803e-01,  5.0056e-01,  2.6761e-01,  ...,  3.9147e-02,\n",
            "            1.8827e-01, -3.1373e-01]],\n",
            "\n",
            "         [[-1.2737e-01,  2.2778e-01, -4.7004e-01,  ...,  3.0710e-01,\n",
            "           -3.0323e-01,  3.1003e-01],\n",
            "          [-7.7340e-02, -9.9540e-01, -3.2337e-02,  ...,  1.6687e-01,\n",
            "            4.6133e-01,  7.3572e-01],\n",
            "          [ 1.9417e-01,  6.4767e-01, -3.1919e-01,  ...,  1.3205e+00,\n",
            "            6.2262e-01,  8.1932e-01],\n",
            "          ...,\n",
            "          [ 6.4790e-01, -2.3236e-01, -4.4700e-03,  ..., -1.2964e+00,\n",
            "            4.4983e-01,  4.2759e-01],\n",
            "          [-6.2489e-02,  4.1055e-01,  3.3341e-01,  ...,  3.2869e-01,\n",
            "            9.4804e-02,  2.1641e-01],\n",
            "          [ 7.7275e-02, -3.0967e-01,  5.5493e-01,  ...,  5.0464e-01,\n",
            "            2.6719e-01, -2.0027e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3247e-01,  3.2461e-01,  1.3642e-01,  ...,  9.6083e-02,\n",
            "           -6.6076e-02, -2.4916e-01],\n",
            "          [-3.5224e-01, -2.1572e-01,  2.4770e-01,  ...,  3.8871e-01,\n",
            "            2.0369e-01, -3.1373e-01],\n",
            "          [ 4.6876e-01, -7.7293e-02,  7.2875e-01,  ...,  3.5810e-01,\n",
            "            1.1309e+00,  7.4253e-01],\n",
            "          ...,\n",
            "          [-3.6197e-01,  3.2201e-01, -2.9637e-01,  ...,  9.5950e-01,\n",
            "           -4.2794e-01, -6.9580e-01],\n",
            "          [ 4.8633e-01, -2.4612e-01,  8.9018e-01,  ..., -3.0633e-01,\n",
            "           -1.1787e-01, -3.4325e-01],\n",
            "          [-3.1204e-01,  1.5970e-01, -1.1081e-01,  ...,  3.7576e-02,\n",
            "           -1.3381e+00,  2.5103e-01]],\n",
            "\n",
            "         [[-2.1483e-01,  9.6885e-02,  4.3770e-01,  ..., -2.6476e-01,\n",
            "           -3.2375e-01,  1.5962e-01],\n",
            "          [-1.2811e-01,  3.0702e-01,  3.2991e-01,  ...,  7.0113e-02,\n",
            "            3.5902e-01, -1.9057e-01],\n",
            "          [-1.6886e-01,  7.0526e-02,  2.4159e-01,  ..., -3.5900e-01,\n",
            "            2.6227e-02, -6.4376e-01],\n",
            "          ...,\n",
            "          [ 3.9166e-01,  2.0770e-01,  2.1544e-01,  ...,  6.1548e-01,\n",
            "           -6.3292e-01, -4.2505e-01],\n",
            "          [ 4.4975e-01,  1.1665e-01,  8.8078e-01,  ..., -2.7104e-01,\n",
            "            4.0519e-01, -5.9963e-02],\n",
            "          [-7.1217e-02,  2.5870e-01,  1.6574e-01,  ..., -8.9273e-03,\n",
            "           -2.4622e-01, -3.4981e-01]],\n",
            "\n",
            "         [[ 4.1758e-01, -5.5043e-01,  5.0856e-01,  ..., -2.9377e-02,\n",
            "           -1.3698e-01, -3.5177e-01],\n",
            "          [-9.3136e-04, -1.4119e-01,  5.2659e-01,  ...,  6.2825e-02,\n",
            "           -1.2239e-01,  2.4883e-01],\n",
            "          [-3.6537e-01, -4.1235e-01,  2.2262e-01,  ...,  8.8765e-01,\n",
            "           -3.4731e-01, -1.6861e-01],\n",
            "          ...,\n",
            "          [ 2.3121e-01, -4.6278e-01,  3.8652e-01,  ..., -3.5576e-01,\n",
            "            1.1131e-01,  1.4143e-01],\n",
            "          [ 4.6736e-01,  1.3576e-01,  3.7288e-01,  ..., -1.8581e-01,\n",
            "            7.8566e-01, -2.0638e-01],\n",
            "          [-5.9486e-02, -2.1568e-01, -6.4280e-01,  ..., -6.8276e-01,\n",
            "            3.2673e-01,  1.8156e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.2510e-01,  6.5161e-01,  1.3551e-01,  ..., -1.3980e-01,\n",
            "           -4.3667e-02, -1.1797e-01],\n",
            "          [-4.9157e-01, -2.5921e-01,  3.0073e-01,  ..., -1.1707e-01,\n",
            "           -3.7557e-01,  4.1269e-01],\n",
            "          [ 4.3230e-01,  4.0990e-01, -5.8957e-01,  ...,  5.7421e-01,\n",
            "           -4.3484e-01,  2.5595e-01],\n",
            "          ...,\n",
            "          [ 8.9850e-01,  9.9368e-02, -1.4553e+00,  ..., -1.6031e-01,\n",
            "            2.7335e-01,  1.5124e-01],\n",
            "          [ 4.0548e-01, -5.2621e-01,  3.6730e-02,  ...,  7.9713e-02,\n",
            "           -6.6925e-01, -5.0444e-01],\n",
            "          [ 6.0289e-01, -3.2576e-01,  2.9969e-01,  ..., -1.5785e+00,\n",
            "            1.3459e+00,  3.6387e-01]],\n",
            "\n",
            "         [[-1.6612e-01,  3.3552e-01,  1.6422e-02,  ...,  6.2271e-01,\n",
            "            9.9898e-02, -6.0836e-02],\n",
            "          [ 4.3751e-01, -2.5567e-01,  1.0186e+00,  ..., -2.6776e-01,\n",
            "            2.2054e-01, -5.7769e-01],\n",
            "          [-8.0830e-01, -7.3058e-02,  2.9948e-01,  ...,  7.6156e-01,\n",
            "            7.4177e-01, -3.5937e-01],\n",
            "          ...,\n",
            "          [ 7.6684e-01,  1.8072e-01, -3.8867e-01,  ...,  4.5491e-01,\n",
            "           -2.2622e-01, -5.3123e-01],\n",
            "          [ 4.2535e-01, -6.7050e-01,  5.5846e-01,  ..., -2.2393e-01,\n",
            "           -1.6501e-01, -2.3848e-01],\n",
            "          [ 3.9613e-01, -2.7700e-01,  4.8823e-01,  ...,  2.4235e-02,\n",
            "           -7.1169e-01,  4.9545e-01]],\n",
            "\n",
            "         [[-2.4019e-01, -6.3651e-02,  1.3865e-01,  ..., -9.0327e-03,\n",
            "           -6.5891e-02,  5.8568e-01],\n",
            "          [-3.5892e-01, -1.2942e-01,  3.8162e-01,  ...,  5.0237e-01,\n",
            "           -5.6984e-02, -2.2541e-03],\n",
            "          [ 4.0521e-02,  7.4536e-01, -1.3447e+00,  ...,  1.5569e+00,\n",
            "            8.8905e-01, -3.0443e-01],\n",
            "          ...,\n",
            "          [-7.1439e-01, -8.4265e-01,  1.2768e+00,  ..., -1.1431e+00,\n",
            "            3.5093e-01,  3.6488e-01],\n",
            "          [ 4.0470e-01,  2.2870e-01, -7.5103e-01,  ..., -5.1414e-02,\n",
            "           -7.2056e-01, -1.7625e-01],\n",
            "          [ 2.6889e-03,  4.3008e-02,  7.0956e-01,  ..., -6.1658e-01,\n",
            "           -4.3539e-01,  4.8550e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.8804e-01,  7.0084e-03, -3.6914e-02,  ...,  5.5845e-02,\n",
            "            1.8874e-02, -9.6579e-02],\n",
            "          [-1.6072e-03,  3.1645e-01, -5.0371e-02,  ...,  2.2477e-01,\n",
            "            2.5975e-01, -3.7652e-01],\n",
            "          [ 2.4425e-01,  9.3042e-01, -2.6200e-01,  ..., -8.9623e-01,\n",
            "            1.6266e-02, -4.3377e-01],\n",
            "          ...,\n",
            "          [-6.3069e-01, -8.6510e-01,  1.3493e+00,  ...,  4.1715e-01,\n",
            "           -1.7003e-01, -1.5643e-01],\n",
            "          [-2.9056e-01,  1.5002e-02, -2.0764e-02,  ...,  2.8917e-01,\n",
            "            4.1038e-01,  1.1950e-01],\n",
            "          [-3.5991e-02, -7.5838e-01, -4.7449e-01,  ..., -1.9123e-02,\n",
            "           -5.5948e-01,  3.3777e-01]],\n",
            "\n",
            "         [[ 3.5970e-01,  3.1005e-02, -3.2847e-01,  ..., -3.0739e-01,\n",
            "           -3.1803e-01,  4.3415e-01],\n",
            "          [-4.7729e-01,  5.0315e-01,  7.9728e-01,  ..., -4.5070e-01,\n",
            "            7.9938e-01,  1.9115e-01],\n",
            "          [ 4.0335e-01, -4.4459e-01,  8.6452e-01,  ..., -6.0310e-01,\n",
            "           -8.5256e-01,  7.8475e-01],\n",
            "          ...,\n",
            "          [ 1.8896e-01, -8.7212e-02, -2.1098e-01,  ..., -1.3141e-01,\n",
            "            2.6265e-01,  1.6772e-02],\n",
            "          [ 2.6952e-01, -1.2714e-01, -3.7751e-02,  ...,  1.2694e-01,\n",
            "            6.0682e-01, -2.4301e-01],\n",
            "          [ 2.2486e-01,  2.4367e-01, -1.4273e-01,  ..., -3.2002e-03,\n",
            "            3.1576e-01,  2.6116e-01]],\n",
            "\n",
            "         [[-1.9466e-01,  2.6083e-01, -1.4839e-01,  ..., -2.3698e-01,\n",
            "           -8.5889e-02,  2.7994e-01],\n",
            "          [-3.1020e-01,  1.4976e+00, -1.7289e+00,  ..., -2.7006e-02,\n",
            "            3.6200e-02,  1.1390e-01],\n",
            "          [ 5.1765e-01,  8.3128e-01, -2.6598e-01,  ..., -8.5617e-01,\n",
            "           -3.1869e-02, -3.3716e-01],\n",
            "          ...,\n",
            "          [ 1.5757e-01, -4.0905e-01,  4.4193e-01,  ...,  6.5119e-01,\n",
            "           -1.1118e+00, -1.4646e-01],\n",
            "          [-4.6607e-01,  3.9819e-02, -7.4688e-01,  ..., -3.9473e-01,\n",
            "           -2.1408e-01,  5.9853e-01],\n",
            "          [-1.2653e-01, -1.4268e-01, -8.2271e-03,  ...,  1.5719e-01,\n",
            "           -7.7446e-01,  4.0719e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 3.8858e-01, -1.4384e-01, -1.1300e-01,  ...,  3.9162e-01,\n",
            "            1.4542e-01,  3.1082e-01],\n",
            "          [ 3.6819e-01, -4.2185e-01,  6.4633e-01,  ...,  4.4074e-02,\n",
            "            3.4567e-01, -2.4804e-01],\n",
            "          [ 2.7611e-01, -4.2686e-01, -7.3432e-01,  ...,  7.3423e-02,\n",
            "           -4.0081e-01,  4.8702e-01],\n",
            "          ...,\n",
            "          [ 1.0167e-01,  1.0356e+00,  1.5110e-01,  ..., -4.1213e-01,\n",
            "           -1.8920e-01,  6.2152e-01],\n",
            "          [ 4.6774e-01, -2.0156e-01,  1.0090e-01,  ...,  5.6581e-03,\n",
            "           -3.1537e-01, -6.1083e-03],\n",
            "          [-5.8336e-01,  3.5330e-01, -3.9458e-02,  ..., -5.0203e-01,\n",
            "            1.0399e+00,  5.5617e-01]],\n",
            "\n",
            "         [[ 4.4140e-01,  1.8249e-01,  2.8033e-01,  ...,  3.7653e-02,\n",
            "           -4.6919e-02,  5.4832e-01],\n",
            "          [ 2.4006e-01,  1.3362e-01, -2.0055e-01,  ..., -1.1699e+00,\n",
            "            1.6795e-01,  2.6684e-01],\n",
            "          [-7.0666e-02, -9.9301e-01, -2.7070e-01,  ..., -3.8230e-01,\n",
            "            7.2958e-01, -8.1519e-01],\n",
            "          ...,\n",
            "          [ 6.4665e-01,  2.3070e-01,  1.0651e+00,  ...,  2.0932e-01,\n",
            "           -2.0303e-03,  1.6368e-01],\n",
            "          [ 2.5085e-01, -2.6957e-01,  5.1646e-01,  ...,  6.9607e-01,\n",
            "            5.7503e-01,  2.4370e-01],\n",
            "          [ 1.4313e-01,  4.2792e-01, -4.2533e-01,  ...,  3.6586e-01,\n",
            "            4.0287e-01, -1.9669e-01]],\n",
            "\n",
            "         [[ 4.9518e-01, -3.0632e-01,  4.2869e-01,  ...,  3.5573e-03,\n",
            "            1.1729e-01, -3.6075e-01],\n",
            "          [ 2.9786e-01,  1.5773e-01, -1.8744e-01,  ...,  2.7066e-01,\n",
            "            3.5461e-01,  1.2116e+00],\n",
            "          [ 6.9193e-01, -2.4114e-01,  3.3931e-01,  ...,  1.2311e+00,\n",
            "           -6.4835e-01, -1.1454e-01],\n",
            "          ...,\n",
            "          [-6.6902e-03,  2.3865e-02, -4.7859e-01,  ..., -6.4648e-01,\n",
            "            3.4709e-01,  1.9647e-01],\n",
            "          [-3.5850e-01, -5.9300e-01,  1.3680e-01,  ...,  6.5793e-01,\n",
            "           -2.7148e-01, -4.2289e-01],\n",
            "          [-2.7297e-01,  4.2960e-01, -2.4360e-01,  ..., -1.2718e-02,\n",
            "            6.4527e-01,  3.2643e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.7156e-02, -9.2476e-02,  1.6593e-01,  ...,  5.6719e-01,\n",
            "           -9.0092e-02, -1.8305e-01],\n",
            "          [ 1.2978e-01,  9.8116e-01,  3.0113e-02,  ..., -2.2848e-01,\n",
            "            4.9648e-01, -1.4533e-01],\n",
            "          [ 2.9182e-02,  1.4009e+00,  3.3470e-01,  ..., -1.7535e-01,\n",
            "           -1.2057e-01,  8.8214e-01],\n",
            "          ...,\n",
            "          [ 8.8295e-02, -3.2532e-01,  3.3418e-01,  ...,  5.2487e-01,\n",
            "           -6.3227e-01,  2.5783e-01],\n",
            "          [-7.0236e-02,  2.7639e-02,  1.1731e-01,  ..., -7.2089e-01,\n",
            "           -4.5737e-01, -1.0900e-01],\n",
            "          [ 5.2694e-01, -8.4164e-02,  3.2203e-01,  ..., -6.2513e-02,\n",
            "           -2.7663e-02,  5.9386e-01]],\n",
            "\n",
            "         [[ 5.2049e-01, -4.7428e-01,  3.7916e-01,  ...,  2.9382e-01,\n",
            "           -7.3046e-01,  7.1031e-02],\n",
            "          [-2.4034e-01,  6.7877e-01,  4.7539e-01,  ...,  1.2701e-01,\n",
            "            1.1544e-01,  4.0390e-01],\n",
            "          [ 1.0143e-01,  1.7584e-01,  1.3170e-01,  ..., -3.4719e-01,\n",
            "            9.5693e-01,  8.8438e-02],\n",
            "          ...,\n",
            "          [ 5.6141e-01, -1.4710e-02, -1.1024e+00,  ...,  6.6039e-01,\n",
            "           -2.0363e-01,  6.6019e-02],\n",
            "          [ 1.5914e-01,  2.7187e-01,  5.8586e-01,  ...,  5.2993e-02,\n",
            "            6.6946e-01,  2.9209e-01],\n",
            "          [ 3.7583e-01,  3.2977e-01,  4.7304e-01,  ..., -1.5975e-01,\n",
            "           -4.5637e-01,  1.5120e-01]],\n",
            "\n",
            "         [[-4.1061e-01, -3.7736e-01,  3.8405e-01,  ...,  5.4499e-01,\n",
            "           -2.4252e-01, -8.2584e-02],\n",
            "          [-5.5068e-01,  1.5516e-01, -4.4184e-01,  ..., -9.9097e-01,\n",
            "            8.4866e-01,  1.2302e-01],\n",
            "          [-1.6328e-01, -1.1104e-01,  6.8115e-01,  ...,  2.2335e-01,\n",
            "           -7.2173e-02,  3.7732e-02],\n",
            "          ...,\n",
            "          [-2.3193e-01, -4.6284e-01,  1.0197e+00,  ...,  3.7668e-01,\n",
            "            4.4790e-01, -6.0991e-02],\n",
            "          [-2.6771e-01, -5.1977e-01, -1.5509e-01,  ..., -2.9246e-01,\n",
            "            2.9134e-01, -2.3415e-01],\n",
            "          [-2.3216e-01,  1.9293e-01,  4.7985e-01,  ...,  1.7841e-01,\n",
            "           -1.5345e-01,  3.1639e-01]]]], grad_fn=<MkldnnConvolutionBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLqGbclbp3_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09bb62cd-b63d-45a4-fe91-7ba41081592f"
      },
      "source": [
        "output.shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 33, 26, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYeGAJEuneqW"
      },
      "source": [
        "### nn.functional 패키지\n",
        "\n",
        "- 가중치를 직접 선언하여 인자로 넣어줘야함\n",
        "\n",
        "- 예시)\n",
        "  - Convolution functions\n",
        "\n",
        "  - Pooling functions\n",
        "  \n",
        "  - Non-linear activation functions\n",
        "\n",
        "  - Normalization functions\n",
        "\n",
        "  - Linear functions\n",
        "\n",
        "  - Dropout functions\n",
        "  \n",
        "  - Sparse functions\n",
        "  \n",
        "  - Distance functions\n",
        "\n",
        "  - Loss functions\n",
        "  - ..\n",
        "\n",
        "- https://pytorch.org/docs/stable/nn.functional.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpwbO9Dhpflm"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUYaJ5aLqKed"
      },
      "source": [
        "- Convolution Layer 예시 (2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAWLQE2GouHP"
      },
      "source": [
        "filters = torch.randn(8,4,3,3)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWmSlFBrpms1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b425a9ad-30d5-42b6-d8e0-353a35fcb623"
      },
      "source": [
        "inputs = torch.randn(1,4,5,5)\n",
        "conv = F.conv2d(inputs, filters, padding=1)\n",
        "conv.shape"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wah4RsmgrRDP"
      },
      "source": [
        "## Torchvision\n",
        "\n",
        "- `transforms`: 전처리할 때 사용하는 메소드\n",
        "\n",
        "- `transforms`에서 제공하는 클래스 이외에  \n",
        "  일반적으로 클래스를 따로 만들어 전처리 단계를 진행\n",
        "  \n",
        "  - 아래의 코드에서 다양한 전처리 기술 확인  \n",
        "    https://pytorch.org/docs/stable/torchvision/transforms.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akvq4QWmqSil"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKu5mzyTs-Qj"
      },
      "source": [
        "- 예시)\n",
        "  - `DataLoader`의 인자로 들어갈 `transform`을 미리 정의할 수 있음\n",
        "\n",
        "  - `Compose`를 통해 리스트 안에 순서대로 전처리 진행\n",
        "\n",
        "  - 대표적인 예로, `ToTensor`()를 하는 이유는  \n",
        "   <u>torchvision이 PIL Image형태로만 입력을 받기 때문에</u> 데이터 처리를 위해서 Tensor형으로 변환해야함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6K7FH-Rs9my"
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=(0.5,), std=(0.5,))])"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4l1GvIlslKa"
      },
      "source": [
        "## utils.data\n",
        "\n",
        "- `Dataset`에는 다양한 데이터셋이 존재  \n",
        "  - MNIST, CIFAR10, ...\n",
        "\n",
        "- `DataLoader`, `Dataset`을 통해  \n",
        "  `batch_size`, `train`여부, `transform`등을 인자로 넣어 데이터를 어떻게 load할 것인지 정해줄 수 있음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wsZKY7-s2Vv"
      },
      "source": [
        "import torch \n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "# 1:08:36"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lldpI2lquBu3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKddZnT1uQmT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrxymquLxeo8"
      },
      "source": [
        "- `batch_size`만큼 데이터를 하나씩 가져옴"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvgMIyF6uUuU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPUC0a0aw6OM"
      },
      "source": [
        "<u>**(중요) torch에서는 channel(채널)이 앞에 옴**</u>\n",
        "\n",
        "- `channel first`\n",
        "\n",
        "- tensorflow, keras 등에서는 channel이 뒤에 옴(`channel last`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuhylD3iyFYr"
      },
      "source": [
        "### 데이터 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9hAQmQlul8P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDcUY6o4xUQp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZmPWiGbxoiW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUOdd4UaxaXO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDQfjw4wxr1z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDCVw59ax3-A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVcWQlxzihtS"
      },
      "source": [
        "## 각 Layer 설명"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGXn1_weif5H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73kJ3heBi26y"
      },
      "source": [
        "### nn.Conv2d\n",
        "\n",
        "- `in_channels`: channel의 갯수\n",
        "\n",
        "- `out_channels`: 출력 채널의 갯수\n",
        "\n",
        "- `kernel_size`: 커널(필터) 사이즈\n",
        "\n",
        "- 텐서플로우, 케라스와 다르게 레이어의 `input`인자에도 값을 집어 넣어줘야함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcHJguyFipTl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWiJbViHjFG0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxWYFm2xjUeN"
      },
      "source": [
        "- `wegiht`확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za0enRbyjPzV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAZcTU2gjiCX"
      },
      "source": [
        "- `weight`는 `detach()`를 통해 꺼내줘야 `numpy()`변환이 가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eN_oUBkjT85"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwso9tsijmz8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUegf6HPjdPl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMeTOqVmcdWa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvolnNsscdHs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLOAfD5mjup1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r50wFkl6j1sY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiIp-frJj2Hl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOHMu-UQkW3a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sCqGmH_kwHm"
      },
      "source": [
        "### Pooling\n",
        "- `F.max_pool2d` \n",
        "  - `stride`\n",
        "\n",
        "  - `kernel_size`\n",
        "\n",
        "- `torch.nn.MaxPool2d` 도 많이 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYqPrLH1kxQl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvI8W_8Yk81S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV3HK4FulCaJ"
      },
      "source": [
        "- MaxPool Layer는 weight가 없기 때문에 바로 `numpy()`변환 가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fseB_qlflBta"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w8DQnNtlNCq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7RVioKwlbH1"
      },
      "source": [
        "### Linear\n",
        "- 1d만 가능 `.view()`를 통해 1D로 펼쳐줘야함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwcedadrlcbl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mYQy4I3lmAm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wgSmY0Zlofk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcJFqf0alsxr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewEpebSVluHz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IjPKDKRl3CV"
      },
      "source": [
        "### Softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obhBb3O-lzbs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljgOEyNMmBEE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18ymFSRAmBo7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYh13Bnj5wEN"
      },
      "source": [
        "### F.relu\n",
        "\n",
        "- ReLU 함수를 적용하는 레이어\n",
        "\n",
        "- `nn.ReLU`로도 사용 가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4VFePpR9_Ak"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lKlSiaY5wZW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yuABl4h-yye"
      },
      "source": [
        "## Optimizer\n",
        "\n",
        "- `import torch.optim as optim`\n",
        "\n",
        "- `model`의 파라미터를 업데이트\n",
        "\n",
        "- 예시)\n",
        "  ```python\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "  optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "  ```\n",
        "\n",
        "- `.zero_grad()`로 초기화\n",
        "- `.step()`으로 업데이트\n",
        "\n"
      ]
    }
  ]
}